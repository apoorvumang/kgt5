{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49aba755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d5f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def numLines(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "def loadData(filename, max_points):\n",
    "    file_len = numLines(filename)\n",
    "    f = open(filename, 'r')\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in tqdm(range(file_len)):\n",
    "        if i == max_points:\n",
    "            break\n",
    "        line = f.readline()\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        line = line.split('\\t')\n",
    "        inputs.append(line[0])\n",
    "        outputs.append(line[1])\n",
    "    data = {'inputs': inputs, 'outputs': outputs}\n",
    "    return data\n",
    "        \n",
    "def load_entity_strings(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    return lines\n",
    "\n",
    "def get_entity_wd_id_dict(filename):\n",
    "    out = {}\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        line = line.split('\\t')\n",
    "        out[line[1]] = line[0]\n",
    "    return out\n",
    "    \n",
    "\n",
    "def create_filter_dict(data) -> Dict[str, int]:\n",
    "    filter_dict = defaultdict(list)\n",
    "    for input, output in tqdm(zip(data[\"inputs\"], data[\"outputs\"])):\n",
    "        filter_dict[input].append(output)\n",
    "    return filter_dict\n",
    "\n",
    "def getAllFilteringEntities(input, filter_dicts):\n",
    "    entities = []\n",
    "    splits = ['train', 'test', 'valid']\n",
    "    for s in splits:\n",
    "        entities.extend(filter_dicts[s][input])\n",
    "    return list(set(entities))\n",
    "\n",
    "def wikidata_link_from_id(id):\n",
    "    uri = 'https://www.wikidata.org/wiki/' + id\n",
    "    return uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255f8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'olpbench'\n",
    "# entity_strings = load_entity_strings(os.path.join(\"data\", dataset_name, \"entity_strings.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ee97cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_strings_set = set(entity_strings)\n",
    "# len(entity_strings_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51647083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7354739b6f0641c097e4b2a0eaee615b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61301566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f9ab85671a432caf68beb92c0e5ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9e684a37c94429b643cbde762c5771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {}\n",
    "splits = ['train', 'valid', 'test']\n",
    "dataset_name = 'olpbench'\n",
    "for split in splits:\n",
    "    data[split] = loadData(os.path.join('data', dataset_name, split + '.txt'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616e3b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb5a9c23a2843bc8fa96a0f841734e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b3d3d86bf64e81abab9cd70b5f2e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d4f86888ba482086c0f198b56803cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_dicts = {}\n",
    "splits = ['train', 'valid', 'test']\n",
    "for split in splits:\n",
    "    filter_dicts[split] = create_filter_dict(data[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "13a5a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = 'scores.pickle'\n",
    "# fname = 'scores/scores_full_codexm_small.pickle'\n",
    "fname = 'scores/scores_a.pickle'\n",
    "# fname = 'scores_500_base_trie.pickle'\n",
    "scores_data = pickle.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28465b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict tail: london | has:impl_poss-clause zonal fare system used by | the london underground\n",
      "the saskatchewan railway\n"
     ]
    }
   ],
   "source": [
    "id = 2\n",
    "print(scores_data['input_strings'][id], scores_data['target_strings'][id])\n",
    "print(scores_data['prediction_strings'][id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "02ee6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "def load_test_data_olpbench(fname):\n",
    "    # assumes linked data format\n",
    "    # s r o s1|||s2... o1|||o2...\n",
    "    f = open(fname)\n",
    "    tuples = []\n",
    "    for line in f:\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        line = line.split('\\t')\n",
    "        tuples.append(line)\n",
    "    out = []\n",
    "    for t in tqdm(tuples):\n",
    "        for s_id, o_id in zip([3,4],[4,3]):\n",
    "            rel = t[1]\n",
    "            s = unidecode(t[s_id]).split('|||')\n",
    "            o = unidecode(t[o_id]).split('|||')\n",
    "            out.append((s, rel, o))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "869b28ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc8de5720fa4993b7f72e8e7dfa287e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = load_test_data_olpbench('data/olpbench/test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ecf0f6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the station\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['the gjovik line'],\n",
       " 'is located on',\n",
       " ['a train station',\n",
       "  'a station',\n",
       "  'the station',\n",
       "  'a railway station',\n",
       "  'train stations'])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 117\n",
    "print(scores_data['prediction_strings'][id])\n",
    "test_data[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "69bac626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_data['prediction_strings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e5d40683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "76\n",
      "117\n",
      "202\n",
      "206\n",
      "232\n",
      "238\n",
      "255\n",
      "264\n",
      "284\n",
      "334\n",
      "402\n",
      "406\n",
      "636\n",
      "751\n",
      "786\n",
      "800\n",
      "852\n",
      "860\n",
      "863\n",
      "925\n",
      "926\n",
      "988\n",
      "1000\n",
      "1022\n",
      "1033\n",
      "1044\n",
      "1092\n",
      "1114\n",
      "1141\n",
      "1159\n",
      "1362\n",
      "1434\n",
      "1456\n",
      "1460\n",
      "1463\n",
      "1478\n",
      "1496\n",
      "1544\n",
      "1604\n",
      "1615\n",
      "1646\n",
      "1721\n",
      "1726\n",
      "1730\n",
      "1760\n",
      "1774\n",
      "1809\n",
      "1815\n",
      "1822\n",
      "1828\n",
      "1924\n",
      "1960\n",
      "1988\n",
      "2000\n",
      "2055\n",
      "2140\n",
      "2162\n",
      "2183\n",
      "2305\n",
      "2364\n",
      "2375\n",
      "2376\n",
      "2394\n",
      "2536\n",
      "2578\n",
      "2610\n",
      "2645\n",
      "2735\n",
      "2788\n",
      "2818\n",
      "2822\n",
      "2874\n",
      "2936\n",
      "2939\n",
      "3022\n",
      "3048\n",
      "3186\n",
      "3215\n",
      "3218\n",
      "3227\n",
      "3228\n",
      "3254\n",
      "3270\n",
      "3282\n",
      "3302\n",
      "3384\n",
      "3400\n",
      "3480\n",
      "3516\n",
      "3560\n",
      "3766\n",
      "3776\n",
      "3787\n",
      "3826\n",
      "3835\n",
      "3857\n",
      "3898\n",
      "3916\n",
      "3952\n",
      "3966\n",
      "3995\n",
      "3996\n",
      "4003\n",
      "4027\n",
      "4077\n",
      "4145\n",
      "4149\n",
      "4175\n",
      "4178\n",
      "4204\n",
      "4270\n",
      "4310\n",
      "4315\n",
      "4342\n",
      "4374\n",
      "4417\n",
      "4424\n",
      "4438\n",
      "4476\n",
      "4505\n",
      "4538\n",
      "4580\n",
      "4585\n",
      "4612\n",
      "4620\n",
      "4663\n",
      "4673\n",
      "4732\n",
      "4807\n",
      "4810\n",
      "4813\n",
      "4824\n",
      "4828\n",
      "4882\n",
      "4974\n",
      "5083\n",
      "5119\n",
      "5124\n",
      "5153\n",
      "5223\n",
      "5316\n",
      "5336\n",
      "5346\n",
      "5348\n",
      "5364\n",
      "5387\n",
      "5403\n",
      "5430\n",
      "5446\n",
      "5454\n",
      "5460\n",
      "5464\n",
      "5514\n",
      "5536\n",
      "5546\n",
      "5593\n",
      "5664\n",
      "5725\n",
      "5737\n",
      "5784\n",
      "5800\n",
      "5813\n",
      "5852\n",
      "5858\n",
      "5876\n",
      "5912\n",
      "5916\n",
      "5950\n",
      "6014\n",
      "6041\n",
      "6058\n",
      "6129\n",
      "6213\n",
      "6216\n",
      "6238\n",
      "6294\n",
      "6316\n",
      "6329\n",
      "6336\n",
      "6345\n",
      "6398\n",
      "6450\n",
      "6471\n",
      "6478\n",
      "6517\n",
      "6545\n",
      "6546\n",
      "6554\n",
      "6558\n",
      "6596\n",
      "6619\n",
      "6654\n",
      "6669\n",
      "6678\n",
      "6692\n",
      "6718\n",
      "6741\n",
      "6747\n",
      "6778\n",
      "6820\n",
      "6844\n",
      "6860\n",
      "6873\n",
      "6890\n",
      "6914\n",
      "6992\n",
      "7012\n",
      "7110\n",
      "7147\n",
      "7168\n",
      "7219\n",
      "7292\n",
      "7301\n",
      "7314\n",
      "7317\n",
      "7320\n",
      "7354\n",
      "7358\n",
      "7424\n",
      "7426\n",
      "7578\n",
      "7616\n",
      "7636\n",
      "7642\n",
      "7664\n",
      "7685\n",
      "7695\n",
      "7766\n",
      "7938\n",
      "7954\n",
      "7994\n",
      "8034\n",
      "8042\n",
      "8044\n",
      "8085\n",
      "8092\n",
      "8206\n",
      "8208\n",
      "8221\n",
      "8266\n",
      "8286\n",
      "8347\n",
      "8368\n",
      "8377\n",
      "8476\n",
      "8504\n",
      "8516\n",
      "8526\n",
      "8544\n",
      "8576\n",
      "8765\n",
      "8802\n",
      "8816\n",
      "8836\n",
      "8860\n",
      "8904\n",
      "8918\n",
      "8940\n",
      "8944\n",
      "9118\n",
      "9130\n",
      "9141\n",
      "9278\n",
      "9338\n",
      "9357\n",
      "9402\n",
      "9480\n",
      "9549\n",
      "9572\n",
      "9574\n",
      "9618\n",
      "9652\n",
      "9679\n",
      "9723\n",
      "9729\n",
      "9757\n",
      "9804\n",
      "9818\n",
      "9853\n",
      "9856\n",
      "9864\n",
      "9896\n",
      "9965\n",
      "9978\n",
      "9982\n",
      "10035\n",
      "10134\n",
      "10146\n",
      "10297\n",
      "10373\n",
      "10428\n",
      "10478\n",
      "10529\n",
      "10553\n",
      "10572\n",
      "10575\n",
      "10613\n",
      "10634\n",
      "10676\n",
      "10695\n",
      "10700\n",
      "10712\n",
      "10716\n",
      "10748\n",
      "10781\n",
      "10817\n",
      "10820\n",
      "10830\n",
      "10838\n",
      "10886\n",
      "10889\n",
      "10900\n",
      "10902\n",
      "10951\n",
      "10952\n",
      "10959\n",
      "10972\n",
      "10983\n",
      "11203\n",
      "11229\n",
      "11242\n",
      "11245\n",
      "11251\n",
      "11288\n",
      "11446\n",
      "11450\n",
      "11548\n",
      "11586\n",
      "11604\n",
      "11638\n",
      "11686\n",
      "11692\n",
      "11714\n",
      "11788\n",
      "11835\n",
      "11838\n",
      "11858\n",
      "11904\n",
      "11913\n",
      "11980\n",
      "12009\n",
      "12028\n",
      "12065\n",
      "12092\n",
      "12125\n",
      "12189\n",
      "12227\n",
      "12282\n",
      "12292\n",
      "12332\n",
      "12344\n",
      "12390\n",
      "12406\n",
      "12414\n",
      "12520\n",
      "12534\n",
      "12562\n",
      "12587\n",
      "12588\n",
      "12600\n",
      "12780\n",
      "12812\n",
      "12844\n",
      "12875\n",
      "12904\n",
      "12959\n",
      "12996\n",
      "13006\n",
      "13008\n",
      "13018\n",
      "13027\n",
      "13032\n",
      "13056\n",
      "13168\n",
      "13202\n",
      "13266\n",
      "13326\n",
      "13352\n",
      "13418\n",
      "13450\n",
      "13472\n",
      "13476\n",
      "13479\n",
      "13562\n",
      "13582\n",
      "13614\n",
      "13617\n",
      "13659\n",
      "13699\n",
      "13732\n",
      "13751\n",
      "13767\n",
      "13793\n",
      "13872\n",
      "13888\n",
      "13900\n",
      "13916\n",
      "13953\n",
      "13975\n",
      "14054\n",
      "14059\n",
      "14062\n",
      "14082\n",
      "14139\n",
      "14222\n",
      "14242\n",
      "14278\n",
      "14292\n",
      "14307\n",
      "14336\n",
      "14414\n",
      "14442\n",
      "14456\n",
      "14465\n",
      "14485\n",
      "14495\n",
      "14518\n",
      "14542\n",
      "14620\n",
      "14670\n",
      "14708\n",
      "14739\n",
      "14742\n",
      "14825\n",
      "14842\n",
      "14890\n",
      "14971\n",
      "15034\n",
      "15151\n",
      "15154\n",
      "15180\n",
      "15194\n",
      "15197\n",
      "15228\n",
      "15238\n",
      "15252\n",
      "15277\n",
      "15289\n",
      "15315\n",
      "15372\n",
      "15424\n",
      "15434\n",
      "15466\n",
      "15494\n",
      "15550\n",
      "15673\n",
      "15738\n",
      "15744\n",
      "15842\n",
      "15846\n",
      "15880\n",
      "15901\n",
      "15953\n",
      "15974\n",
      "15986\n",
      "16030\n",
      "16036\n",
      "16067\n",
      "16143\n",
      "16146\n",
      "16158\n",
      "16186\n",
      "16218\n",
      "16232\n",
      "16256\n",
      "16313\n",
      "16320\n",
      "16324\n",
      "16346\n",
      "16364\n",
      "16408\n",
      "16432\n",
      "16436\n",
      "16552\n",
      "16554\n",
      "16575\n",
      "16578\n",
      "16588\n",
      "16610\n",
      "16782\n",
      "16866\n",
      "16877\n",
      "16914\n",
      "16958\n",
      "16980\n",
      "16993\n",
      "17034\n",
      "17047\n",
      "17088\n",
      "17098\n",
      "17133\n",
      "17154\n",
      "17212\n",
      "17258\n",
      "17276\n",
      "17301\n",
      "17320\n",
      "17378\n",
      "17396\n",
      "17422\n",
      "17436\n",
      "17438\n",
      "17469\n",
      "17550\n",
      "17553\n",
      "17630\n",
      "17633\n",
      "17640\n",
      "17648\n",
      "17657\n",
      "17675\n",
      "17707\n",
      "17732\n",
      "17756\n",
      "17758\n",
      "17769\n",
      "17852\n",
      "17880\n",
      "17916\n",
      "17928\n",
      "17961\n",
      "17975\n",
      "17997\n",
      "18122\n",
      "18148\n",
      "18149\n",
      "18206\n",
      "18228\n",
      "18234\n",
      "18242\n",
      "18321\n",
      "18375\n",
      "18393\n",
      "18427\n",
      "18440\n",
      "18474\n",
      "18569\n",
      "18598\n",
      "18652\n",
      "18679\n",
      "18697\n",
      "18708\n",
      "18745\n",
      "18786\n",
      "18860\n",
      "18874\n",
      "18890\n",
      "18921\n",
      "18928\n",
      "18955\n",
      "18984\n",
      "19000\n",
      "19007\n",
      "19016\n",
      "19100\n",
      "19133\n",
      "19149\n",
      "19154\n",
      "19178\n",
      "19296\n",
      "19305\n",
      "19321\n",
      "19337\n",
      "19349\n",
      "19359\n",
      "19388\n",
      "19503\n",
      "19513\n",
      "19541\n",
      "19596\n",
      "19637\n",
      "19665\n",
      "19683\n",
      "19702\n",
      "19721\n",
      "19722\n",
      "19845\n",
      "19920\n",
      "19947\n",
      "19952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02905"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for id in range(len(scores_data['prediction_strings'])):\n",
    "    targets = test_data[id][2]\n",
    "    predictions = scores_data['prediction_strings'][id]\n",
    "    # if 1 predictions make array\n",
    "    predictions = [predictions]\n",
    "    if len(set(targets).intersection(set(predictions))) > 0:\n",
    "        count += 1\n",
    "        print(id)\n",
    "total_count = len(scores_data['prediction_strings'])\n",
    "count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f110a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bff88b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61244it [00:11, 5378.53it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_scores_dicts = []\n",
    "for string_arr, score_arr in tqdm(zip(scores_data['prediction_strings'], scores_data['scores'])):\n",
    "    ps_pairs = [(p,s) for p,s in zip(string_arr, score_arr)]\n",
    "    ps_pairs = list(set(ps_pairs)) # while sampling, duplicates are created\n",
    "    # remove predictions that are not entities\n",
    "    ps_dict_only_entities = defaultdict(list)\n",
    "    for ps in ps_pairs:\n",
    "        if ps[0] in entity_strings_set:\n",
    "            ps_dict_only_entities[ps[0]] = ps[1]\n",
    "    predictions_scores_dicts.append(ps_dict_only_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45377700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(predictions_scores_dicts[x]) for x in range(500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f565355b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict tail: vietnam | diplomatic relation | mexico\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'serbia': -3.3982773,\n",
       "             'luxembourg': -4.66638,\n",
       "             'indonesia': -3.5668106,\n",
       "             'germany': -3.5101147,\n",
       "             'mexico': -3.095539,\n",
       "             'brazil': -5.24856,\n",
       "             'italy': -3.5092916,\n",
       "             'ukraine': -4.684395,\n",
       "             'cambodia': -4.270482,\n",
       "             'spain': -3.7536564,\n",
       "             'saudi arabia': -3.193513,\n",
       "             'soviet union': -5.5200253,\n",
       "             'mongolia': -3.908885,\n",
       "             'greece': -5.595957,\n",
       "             'european union': -5.8609905,\n",
       "             'denmark': -3.6262321,\n",
       "             'laos': -3.848981,\n",
       "             'bangladesh': -3.5050812,\n",
       "             'philippines': -3.3096695,\n",
       "             'poland': -5.6494665,\n",
       "             'bulgaria': -3.183054,\n",
       "             'australia': -3.7198315,\n",
       "             'cuba': -4.132122,\n",
       "             'singapore': -4.7629385,\n",
       "             'vietnam': -4.123703,\n",
       "             'turkey': -5.0184784,\n",
       "             'georgia': -4.5141897,\n",
       "             'angola': -5.0547733,\n",
       "             'austria': -3.7758741,\n",
       "             'romania': -4.5870094,\n",
       "             'venezuela': -3.3012657,\n",
       "             'israel': -5.064765,\n",
       "             'india': -3.090887,\n",
       "             \"people's republic of china\": -3.6069994,\n",
       "             'holy see': -4.3225822,\n",
       "             'taiwan': -3.2550182,\n",
       "             'north korea': -3.3946123,\n",
       "             'russia': -3.4549417,\n",
       "             'pakistan': -4.348446,\n",
       "             'united states of america': -3.6606464,\n",
       "             'japan': -4.937191,\n",
       "             'state of palestine': -4.03078,\n",
       "             'france': -3.7842083,\n",
       "             'malaysia': -3.888729,\n",
       "             'south korea': -3.6449738,\n",
       "             'hungary': -3.3495169})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 2\n",
    "print(scores_data['input_strings'][id], scores_data['target_strings'][id])\n",
    "# print(scores_data['scores'][2])\n",
    "predictions_scores_dicts[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89828715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61244"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_scores_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf0d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 61244/61244 [00:29<00:00, 2083.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374.5308111815034 1.9256090392528247\n",
      "0.36741558356736986\n",
      "14383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions_filtered = []\n",
    "head_num_filter = 0\n",
    "tail_num_filter = 0\n",
    "hits_at_all = 0\n",
    "count = 0\n",
    "for i in tqdm(range(len(predictions_scores_dicts))):\n",
    "    ps_dict = predictions_scores_dicts[i].copy()\n",
    "    target = scores_data['target_strings'][i]\n",
    "    inputs = scores_data['input_strings'][i]\n",
    "    prediction_strings = ps_dict.keys()\n",
    "    if target in prediction_strings:\n",
    "        original_score = ps_dict[target]\n",
    "    # get filtering entities\n",
    "    filtering_entities = getAllFilteringEntities(inputs, filter_dicts)\n",
    "    if len(filtering_entities) == 1:\n",
    "        count += 1\n",
    "    if 'head' in inputs:\n",
    "        head_num_filter += len(filtering_entities)\n",
    "    else:\n",
    "        tail_num_filter += len(filtering_entities)\n",
    "    for ent in filtering_entities:\n",
    "        if ent in ps_dict:\n",
    "            ps_dict[ent] = -float(\"inf\")\n",
    "    if target in prediction_strings:\n",
    "        ps_dict[target] = original_score\n",
    "        hits_at_all += 1\n",
    "    # softmax for scores\n",
    "    names_arr = []\n",
    "    scores_arr = []\n",
    "    for k, v in ps_dict.items():\n",
    "        names_arr.append(k)\n",
    "        scores_arr.append(v)\n",
    "    scores_arr = np.array(scores_arr)\n",
    "#     scores_arr = softmax(scores_arr)\n",
    "    for name, score in zip(names_arr, scores_arr):\n",
    "        ps_dict[name] = score\n",
    "    predictions_filtered.append(ps_dict)\n",
    "print(head_num_filter/len(predictions_filtered), tail_num_filter/len(predictions_filtered))\n",
    "print(hits_at_all/len(predictions_filtered))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde8c8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@1 0.2106002220625694\n",
      "hits@3 0.28918751224609757\n",
      "hits@10 0.3459440924825289\n",
      "mrr 0.2571287581304741\n",
      "0.08693096466592645 were <10 length preds array without answer\n"
     ]
    }
   ],
   "source": [
    "count = {}\n",
    "reciprocal_ranks = 0.0\n",
    "k_list = [1,3,10]\n",
    "for k in k_list:\n",
    "    count[k] = 0\n",
    "num_small_arrs = 0\n",
    "count2 = 0\n",
    "for i in range(len(predictions_filtered)):\n",
    "    target = scores_data['target_strings'][i]\n",
    "    ps_dict = predictions_filtered[i]\n",
    "    ps_sorted = sorted(ps_dict.items(), key=lambda item: -item[1])\n",
    "    if len(ps_dict) == 0:\n",
    "        preds = []\n",
    "    else:\n",
    "        preds = [x[0] for x in ps_sorted]\n",
    "    if target in preds:\n",
    "        rank = preds.index(target) + 1\n",
    "        reciprocal_ranks += 1./rank\n",
    "    for k in k_list:\n",
    "        if target in preds[:k]:\n",
    "            count[k] += 1\n",
    "    if len(preds) < 10 and target not in preds:\n",
    "        num_small_arrs += 1\n",
    "    if target in preds:\n",
    "        count2 += 1\n",
    "for k in k_list:\n",
    "    hits_at_k = count[k]/len(predictions_filtered)\n",
    "    print('hits@{}'.format(k), hits_at_k)\n",
    "print('mrr', reciprocal_ranks/len(predictions_filtered))\n",
    "print(num_small_arrs/len(predictions_filtered), 'were <10 length preds array without answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e531dfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4732324701774804"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count2/len(predictions_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8b079bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 4\n",
    "inputs = scores_data['input_strings'][id]\n",
    "preds = predictions_filtered[id]\n",
    "preds = sorted(preds.items(), key=lambda item: -item[1])\n",
    "target = scores_data['target_strings'][id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75768b24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict tail: Valenciennes | isLocatedIn | Target: Nord-Pas-de-Calais\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('Île-de-France', 0.3138781066564107),\n",
       "  ('Lower_Silesian_Voivodeship', 0.13227073610334242),\n",
       "  ('Nord-Pas-de-Calais', 0.09675851055651631),\n",
       "  ('Valenciennes', 0.07590361486184467),\n",
       "  ('Lists_of_World_Heritage_Sites_in_Europe', 0.061758891746029325),\n",
       "  ('Centre_region,_France', 0.052148043026076424),\n",
       "  ('Lesser_Poland_Voivodeship', 0.044005159013402746),\n",
       "  ('Pays_de_la_Loire', 0.04173769409652669),\n",
       "  ('Paris', 0.03586650379301719),\n",
       "  ('Quebec', 0.030035223333408627)],\n",
       " 'Nord-Pas-de-Calais')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs, 'Target:', target)\n",
    "preds[:10], target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "b8d6fa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 predict tail: ali kazemaini | birthplace | tehran\n",
      "34 predict tail: ashta, maharashtra | instance of | human settlement\n",
      "37 predict tail: roy shaw 0 | instance of | human being\n",
      "40 predict tail: t. canby jones | has surname | jones (family name)\n",
      "45 predict tail: naveen kumar | instance of | human being\n",
      "46 predict tail: barlow respiratory hospital | host country | united states of america\n",
      "48 predict tail: camiling | office held by head of government | mayor\n",
      "51 predict tail: hazel soan | instance of | human being\n",
      "52 predict tail: efrain herrera | sport played | association football\n",
      "53 predict tail: oluf munck | instance of | human being\n",
      "54 predict tail: thomas gilchrist | instance of | human being\n",
      "58 predict tail: desmoplastic fibroma | subclass of | fibroma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('count', 12)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only head/tails\n",
    "count = 0\n",
    "for id in range(60,120, 2):\n",
    "    inputs = scores_data['input_strings'][id]\n",
    "    preds = predictions_filtered[id]\n",
    "    preds = sorted(preds.items(), key=lambda item: -item[1])\n",
    "    target = scores_data['target_strings'][id]\n",
    "    pred1 = preds[0][0]\n",
    "    if pred1 == target:\n",
    "        print(int(id/2), inputs, pred1)\n",
    "        count += 1\n",
    "'count', count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "811dccc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "print(\"<a href='your_url_here'>Showing Text</a>\")\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "print(\"<a href='your_url_here'>Showing Text</a>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "36ee8176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q4121082'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2wdid['pakistan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8dee3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = ['english', 'english language', 'french']\n",
    "t = Trie(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fdb192fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6aa43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

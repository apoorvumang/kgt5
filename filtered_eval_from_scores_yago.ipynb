{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49aba755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d5f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def numLines(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "def loadData(filename, max_points):\n",
    "    file_len = numLines(filename)\n",
    "    f = open(filename, 'r')\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in tqdm(range(file_len)):\n",
    "        if i == max_points:\n",
    "            break\n",
    "        line = f.readline()\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        line = line.split('\\t')\n",
    "        inputs.append(line[0])\n",
    "        outputs.append(line[1])\n",
    "    data = {'inputs': inputs, 'outputs': outputs}\n",
    "    return data\n",
    "        \n",
    "def load_entity_strings(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    return lines\n",
    "\n",
    "def get_entity_wd_id_dict(filename):\n",
    "    out = {}\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        line = line.split('\\t')\n",
    "        out[line[1]] = line[0]\n",
    "    return out\n",
    "    \n",
    "\n",
    "def create_filter_dict(data) -> Dict[str, int]:\n",
    "    filter_dict = defaultdict(list)\n",
    "    for input, output in zip(data[\"inputs\"], data[\"outputs\"]):\n",
    "        filter_dict[input].append(output)\n",
    "    return filter_dict\n",
    "\n",
    "def getAllFilteringEntities(input, filter_dicts):\n",
    "    entities = []\n",
    "    splits = ['train', 'test', 'valid']\n",
    "    for s in splits:\n",
    "        entities.extend(filter_dicts[s][input])\n",
    "    return list(set(entities))\n",
    "\n",
    "def wikidata_link_from_id(id):\n",
    "    uri = 'https://www.wikidata.org/wiki/' + id\n",
    "    return uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255f8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'yago3-10_2'\n",
    "entity_strings = load_entity_strings(os.path.join(\"data\", dataset_name, \"entity_strings.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ee97cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_strings_set = set(entity_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51647083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 2158080/2158080 [00:01<00:00, 1116726.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 595046.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 560983.32it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "splits = ['train', 'valid', 'test']\n",
    "dataset_name = 'yago3-10_2'\n",
    "for split in splits:\n",
    "    data[split] = loadData(os.path.join('data', dataset_name, split + '.txt'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "616e3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dicts = {}\n",
    "splits = ['train', 'valid', 'test']\n",
    "for split in splits:\n",
    "    filter_dicts[split] = create_filter_dict(data[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a5a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = 'scores.pickle'\n",
    "fname = 'scores/scores_full_yago2.pickle'\n",
    "# fname = 'scores_500_base_trie.pickle'\n",
    "scores_data = pickle.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bff88b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:01, 7107.19it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_scores_dicts = []\n",
    "for string_arr, score_arr in tqdm(zip(scores_data['prediction_strings'], scores_data['scores'])):\n",
    "    ps_pairs = [(p,s) for p,s in zip(string_arr, score_arr)]\n",
    "    ps_pairs = list(set(ps_pairs)) # while sampling, duplicates are created\n",
    "    # remove predictions that are not entities\n",
    "    ps_dict_only_entities = defaultdict(list)\n",
    "    for ps in ps_pairs:\n",
    "        if ps[0] in entity_strings_set:\n",
    "            ps_dict_only_entities[ps[0]] = ps[1]\n",
    "    predictions_scores_dicts.append(ps_dict_only_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45377700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(predictions_scores_dicts[x]) for x in range(500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe558d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_scores_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cf0d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1816.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1826.6029, 4.5389, 6084)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions_filtered = []\n",
    "head_num_filter = 0\n",
    "tail_num_filter = 0\n",
    "count = 0\n",
    "for i in tqdm(range(len(predictions_scores_dicts))):\n",
    "    ps_dict = predictions_scores_dicts[i].copy()\n",
    "    target = scores_data['target_strings'][i]\n",
    "    inputs = scores_data['input_strings'][i]\n",
    "    prediction_strings = ps_dict.keys()\n",
    "    if target in prediction_strings:\n",
    "        original_score = ps_dict[target]\n",
    "    # get filtering entities\n",
    "    filtering_entities = getAllFilteringEntities(inputs, filter_dicts)\n",
    "    if len(filtering_entities) <= 20:\n",
    "        count += 1\n",
    "    if 'head' in inputs:\n",
    "        head_num_filter += len(filtering_entities)\n",
    "    else:\n",
    "        tail_num_filter += len(filtering_entities)\n",
    "    for ent in filtering_entities:\n",
    "        if ent in ps_dict:\n",
    "            ps_dict[ent] = -float(\"inf\")\n",
    "    if target in prediction_strings:\n",
    "        ps_dict[target] = original_score\n",
    "    # softmax for scores\n",
    "    names_arr = []\n",
    "    scores_arr = []\n",
    "    for k, v in ps_dict.items():\n",
    "        names_arr.append(k)\n",
    "        scores_arr.append(v)\n",
    "    scores_arr = np.array(scores_arr)\n",
    "#     scores_arr = softmax(scores_arr)\n",
    "    for name, score in zip(names_arr, scores_arr):\n",
    "        ps_dict[name] = score\n",
    "    predictions_filtered.append(ps_dict)\n",
    "head_num_filter/len(predictions_filtered), tail_num_filter/len(predictions_filtered), count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cde8c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b145667fb5ff41bfa7c580058b36a07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@1 0.49946977730646874\n",
      "hits@3 0.5673382820784729\n",
      "hits@10 0.6171792152704135\n",
      "mrr 0.5397657936869451\n",
      "0.16542948038176034 were <10 length preds array without answer\n",
      "For excel:\n",
      "0.54\n",
      "0.499\n",
      "0.567\n",
      "0.617\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "count = {}\n",
    "reciprocal_ranks = 0.0\n",
    "k_list = [1,3,10]\n",
    "for k in k_list:\n",
    "    count[k] = 0\n",
    "num_small_arrs = 0\n",
    "count2 = 0\n",
    "total_count = 0\n",
    "for i in tqdm(range(len(predictions_filtered))):\n",
    "    target = scores_data['target_strings'][i]\n",
    "    inputs = scores_data['input_strings'][i]\n",
    "    filtering_entities = getAllFilteringEntities(inputs, filter_dicts)\n",
    "    if len(filtering_entities) <= 1:\n",
    "        total_count += 1\n",
    "    else:\n",
    "        continue\n",
    "    ps_dict = predictions_filtered[i]\n",
    "    ps_sorted = sorted(ps_dict.items(), key=lambda item: -item[1])\n",
    "    if len(ps_dict) == 0:\n",
    "        preds = []\n",
    "    else:\n",
    "        preds = [x[0] for x in ps_sorted]\n",
    "    if target in preds:\n",
    "        rank = preds.index(target) + 1\n",
    "        reciprocal_ranks += 1./rank\n",
    "    for k in k_list:\n",
    "        if target in preds[:k]:\n",
    "            count[k] += 1\n",
    "    if len(preds) < 10 and target not in preds:\n",
    "        num_small_arrs += 1\n",
    "    if target in preds:\n",
    "        count2 += 1\n",
    "        \n",
    "# total_count = len(predictions_filtered)\n",
    "for k in k_list:\n",
    "    hits_at_k = count[k]/total_count\n",
    "    print('hits@{}'.format(k), hits_at_k)\n",
    "print('mrr', reciprocal_ranks/total_count)\n",
    "print(num_small_arrs/total_count, 'were <10 length preds array without answer')\n",
    "print('For excel:')\n",
    "print(round(reciprocal_ranks/total_count, 3))\n",
    "for k in k_list:\n",
    "    hits_at_k = count[k]/total_count\n",
    "    print(round(hits_at_k, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c25a20ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.554"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count2/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "8b079bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict head: Portsmouth F.C. | is affiliated to | Target: Mark Blake (footballer born 1970)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('John Wark', -6.662752151489258),\n",
       "  ('James Hurst (footballer)', -7.524306297302246),\n",
       "  ('Paul Moody (footballer)', -7.6999406814575195),\n",
       "  ('Kevin Miller (footballer)', -7.935149192810059),\n",
       "  ('James Baird (footballer)', -8.028887748718262),\n",
       "  ('Bill Rawlings', -8.164727210998535),\n",
       "  ('Bill White (footballer born 1907)', -8.24087142944336),\n",
       "  (\"John O'Rourke (footballer)\", -8.302714347839355),\n",
       "  ('David Knight (English footballer)', -8.331277847290039),\n",
       "  ('Kevin Amankwaah', -8.336922645568848)],\n",
       " 'Mark Blake (footballer born 1970)')"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 23\n",
    "inputs = scores_data['input_strings'][id]\n",
    "preds = predictions_filtered[id]\n",
    "preds = sorted(preds.items(), key=lambda item: -item[1])\n",
    "target = scores_data['target_strings'][id]\n",
    "print(inputs, 'Target:', target)\n",
    "preds[:10], target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "75768b24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict tail: Rosemere, Quebec | is located in | Target: Quebec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('Mauricie', -6.508617401123047),\n",
       "  ('Louiseville', -6.886135101318359),\n",
       "  (\"Marguerite-D'Youville Regional County Municipality\", -6.97409725189209),\n",
       "  ('Burgundy', -7.875734329223633),\n",
       "  ('Urban agglomeration of Longueuil', -10.717867851257324),\n",
       "  ('Therese-De Blainville Regional County Municipality', -inf),\n",
       "  ('Laurentides', -inf)],\n",
       " 'Quebec')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8f0c2f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Johnson (footballer born 1911)\n",
      "Joe Mercer\n",
      "Joe Payne (footballer)\n",
      "Joe Smith (footballer born 1890)\n",
      "Joe Spence (footballer born 1898)\n",
      "Joe Corrigan\n",
      "Joe Baker\n",
      "Joe Smith (football forward born 1889)\n",
      "Joe Bradford\n",
      "Joe Royle\n",
      "Joey Barton\n",
      "Joe Bacuzzi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = getAllFilteringEntities(inputs, filter_dicts)\n",
    "for ent in x:\n",
    "    if 'Joe' in ent:\n",
    "        print(ent)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ad26aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suriname national football team\n",
      "Suriname\n"
     ]
    }
   ],
   "source": [
    "for e in entity_strings:\n",
    "    if 'Surinam' in e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "51def046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelation(input):\n",
    "    relation = input.split('|')[1].strip()\n",
    "    return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6c95b343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plays for\n",
      "plays for\n",
      "is located in\n",
      "plays for\n",
      "plays for\n",
      "has gender\n",
      "plays for\n",
      "plays for\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "plays for\n",
      "plays for\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "plays for\n",
      "has gender\n",
      "plays for\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "acted in\n",
      "acted in\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "plays for\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "plays for\n",
      "plays for\n",
      "plays for\n",
      "plays for\n",
      "plays for\n",
      "plays for\n",
      "wrote music for\n",
      "wrote music for\n",
      "plays for\n",
      "plays for\n",
      "is affiliated to\n",
      "plays for\n",
      "plays for\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "plays for\n",
      "has gender\n",
      "edited\n",
      "edited\n",
      "is affiliated to\n",
      "was born in\n",
      "was born in\n",
      "wrote music for\n",
      "wrote music for\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "is affiliated to\n",
      "plays for\n",
      "plays for\n",
      "is affiliated to\n",
      "plays for\n",
      "edited\n",
      "edited\n"
     ]
    }
   ],
   "source": [
    "for id in range(100):\n",
    "    input=scores_data['input_strings'][id]\n",
    "    preds = predictions_filtered[id]\n",
    "    preds = sorted(preds.items(), key=lambda item: -item[1])\n",
    "    first_pred = preds[0][0]\n",
    "    relation = getRelation(input)\n",
    "    target = scores_data['target_strings'][id]\n",
    "    if target != first_pred:\n",
    "        print(relation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "b8d6fa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 predict tail: ali kazemaini | birthplace | tehran\n",
      "34 predict tail: ashta, maharashtra | instance of | human settlement\n",
      "37 predict tail: roy shaw 0 | instance of | human being\n",
      "40 predict tail: t. canby jones | has surname | jones (family name)\n",
      "45 predict tail: naveen kumar | instance of | human being\n",
      "46 predict tail: barlow respiratory hospital | host country | united states of america\n",
      "48 predict tail: camiling | office held by head of government | mayor\n",
      "51 predict tail: hazel soan | instance of | human being\n",
      "52 predict tail: efrain herrera | sport played | association football\n",
      "53 predict tail: oluf munck | instance of | human being\n",
      "54 predict tail: thomas gilchrist | instance of | human being\n",
      "58 predict tail: desmoplastic fibroma | subclass of | fibroma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('count', 12)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only head/tails\n",
    "count = 0\n",
    "for id in range(60,120, 2):\n",
    "    inputs = scores_data['input_strings'][id]\n",
    "    preds = predictions_filtered[id]\n",
    "    preds = sorted(preds.items(), key=lambda item: -item[1])\n",
    "    target = scores_data['target_strings'][id]\n",
    "    pred1 = preds[0][0]\n",
    "    if pred1 == target:\n",
    "        print(int(id/2), inputs, pred1)\n",
    "        count += 1\n",
    "'count', count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "811dccc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "print(\"<a href='your_url_here'>Showing Text</a>\")\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "print(\"<a href='your_url_here'>Showing Text</a>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "36ee8176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q4121082'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2wdid['pakistan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8dee3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = ['english', 'english language', 'french']\n",
    "t = Trie(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fdb192fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6aa43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

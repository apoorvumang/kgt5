{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "armed-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model args\n",
      "Namespace(batch_size=100, dataset='wikidata5m', epochs=15, learning_rate=None, load_checkpoint='wd5m-sentencepiece-rp/75000.pt', loss_steps=250, max_checkpoints=5, model_size='t5-small', num_workers=3, optimizer='adafactor', relation_prediction=1, resume=None, save_prefix='wd5m-sentencepiece-rp', save_steps=5000, start_steps=0, tokenizer='sentencepiece')\n",
      "Vocab size is 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 10714/10714 [00:00<00:00, 628984.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from utils_accelerate import *\n",
    "import sentencepiece as spm\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "dataset_name = 'wikidata5m'\n",
    "# input = \"predict tail: barack obama | position_held |\"small)1\n",
    "# input = \"translate English to German: How are you doing?\"\n",
    "\n",
    "# model = T5ForConditionalGeneration.from_pretrained('models/codex_m_accelerate_1gpu.pt')\n",
    "# checkpoint_location = 'models/codex_m_accelerate_1gpu/115000.pt'\n",
    "checkpoint_location = 'models/wd5m-sentencepiece-rp/530000.pt'\n",
    "# checkpoint_location = 'models/codex-s_small_1gpu/20000.pt'\n",
    "# checkpoint_location = 'models/codex-m_tiny/70000.pt'\n",
    "# checkpoint_location = 'models/codex-m_small_6gpu/45000.pt'\n",
    "model = load_accelerator_model(checkpoint_location, only_model=True)\n",
    "model.eval()\n",
    "# model.cpu()\n",
    "# model.cuda()\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740f669a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentencepiece_tokenizer import SentencePieceTokenizer\n",
    "\n",
    "tokenizer = SentencePieceTokenizer('wd5m_with_pad', max_tokenize_length=75, pad_to_max=False)\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f035b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "config = T5Config().from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6aed29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"architectures\": [\n",
       "    \"T5WithLMHeadModel\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 8,\n",
       "  \"num_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.3.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95f37628",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"predict tail: united states of america | member of |\"\n",
    "input_ids = tokenizer([input], return_tensors=\"pt\").input_ids # Batch size 1\n",
    "# model.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89e4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5470a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model.sample(input_ids)\n",
    "from transformers import (\n",
    "    LogitsProcessorList,\n",
    "    MinLengthLogitsProcessor,\n",
    "    BeamSearchScorer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e68cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = 'data/codex-m/test.txt'\n",
    "fname = 'data/{}/test.txt'.format(dataset_name)\n",
    "f = open(fname, 'r')\n",
    "data = []\n",
    "for line in f:\n",
    "    data.append(line.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdcdb004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10642"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247d8097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predict tail: walter harris (artist) | country of citizenship |\\tcanada'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c2394bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_wd_id_dict(filename):\n",
    "    out = {}\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        line = line.split('\\t')\n",
    "        out[line[1]] = line[0]\n",
    "    return out\n",
    "\n",
    "e2wdid = get_entity_wd_id_dict('data/wikidata5m/aliases.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240598bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# data_point = 'predict tail: novalis | occupation |    philosopher'\n",
    "id = 2\n",
    "data_point = data[id]\n",
    "encoder_input_str, target = data_point.split('\\t')\n",
    "encoder_input_str = [encoder_input_str]\n",
    "encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "num_beams = 2\n",
    "num_predictions = 2\n",
    "input_ids = torch.ones((len(encoder_input_str) * num_beams, 1), device=model.device, dtype=torch.long)\n",
    "input_ids = input_ids * model.config.decoder_start_token_id\n",
    "model_kwargs = {\n",
    "    \"encoder_outputs\": model.get_encoder()(encoder_input_ids.repeat_interleave(num_beams, dim=0), return_dict=True)\n",
    "}\n",
    "beam_scorer = BeamSearchScorer(\n",
    "    batch_size=len(encoder_input_str),\n",
    "    max_length=model.config.max_length,\n",
    "    num_beams=num_beams,\n",
    "    device=model.device,\n",
    "    num_beam_hyps_to_keep=num_predictions,\n",
    "    length_penalty=0.3\n",
    ")\n",
    "logits_processor = LogitsProcessorList([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3dfe273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict tail: mon oncle benjamin (movie) | original language of film or tv show |\n"
     ]
    }
   ],
   "source": [
    "input = 'predict tail: mon oncle benjamin (movie) | original language of film or tv show |'\n",
    "encoder_input_str = [input]\n",
    "encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "print(encoder_input_str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "eca081b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "languefrancaise\n"
     ]
    }
   ],
   "source": [
    "# outputs = model.beam_search(input_ids, beam_scorer, logits_processor=logits_processor, **model_kwargs)\n",
    "# print(\"Beam:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "outputs = model.generate(encoder_input_ids).tolist()[0]\n",
    "outputs = outputs[1:]\n",
    "outputs = outputs[:outputs.index(2)]\n",
    "print(tokenizer.sp.decode(outputs))\n",
    "# print('Target:', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3d685399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5221150'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2wdid['dante alighieri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b89c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdid2e = {v:k for k, v in e2wdid.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "89bcdafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'original language of film or tv show'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdid2e['P364']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63ef0801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m/s/doculation/doc/docantc'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sp.decode(outputs.tolist()[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf747a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d77eafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGreedyOutput(model, tokenizer, encoder_input_str):\n",
    "    encoder_input_str = [encoder_input_str]\n",
    "    encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(encoder_input_ids)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c64be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeamOutput(model, tokenizer, encoder_input_str, num_beams=10, \n",
    "                  num_predictions=3, length_penalty=1.0):\n",
    "    encoder_input_str = [encoder_input_str]\n",
    "    encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "#     encoder_input_ids = tokenizer(encoder_input_str, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\").input_ids\n",
    "    input_ids = torch.ones((len(encoder_input_str) * num_beams, 1), device=model.device, dtype=torch.long)\n",
    "    input_ids = input_ids * model.config.decoder_start_token_id\n",
    "    model_kwargs = {\n",
    "        \"encoder_outputs\": model.get_encoder()(encoder_input_ids.repeat_interleave(num_beams, dim=0), return_dict=True)\n",
    "    }\n",
    "    beam_scorer = BeamSearchScorer(\n",
    "        batch_size=len(encoder_input_str),\n",
    "        max_length=model.config.max_length,\n",
    "        num_beams=num_beams,\n",
    "        device=model.device,\n",
    "        num_beam_hyps_to_keep=num_predictions,\n",
    "        length_penalty=length_penalty\n",
    "    )\n",
    "    logits_processor = LogitsProcessorList([])\n",
    "    outputs = model.beam_search(input_ids, beam_scorer, logits_processor=logits_processor, **model_kwargs)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23eef50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3944fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:16,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'france', 'united kingdom of great britain and ireland', 'kingdom of italy'} Target: france\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [00:00<00:14,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'jean-baptiste dumas', 'francois-rene de chateaubriand', 'jean-baptiste biot'} Target: gaspard monge\n",
      "Predicted: {'film actor', 'singer-songwriter', 'film producer'} Target: mandolinist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:01<00:10,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julio iglesias', 'julia volkova'} Target: leon russell\n",
      "Predicted: {'film actor', 'singer-songwriter', 'philanthropist'} Target: singer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:01<00:08,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julia volkova', 'idina menzel'} Target: mos def\n",
      "Predicted: {'short story', 'symphony', 'novel'} Target: prose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [00:01<00:09,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'ivan andreyevich krylov', 'j. m. coetzeeeeeeeeeee', 'vladislav krapivin'} Target: max frisch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:02<00:09,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'saint petersburg', 'russian soviet federative socialist republic', 'moscow'} Target: soviet union\n",
      "Predicted: {'russian academy of sciences', 'academy of sciences of the ussr', 'saint petersburg academy of sciences'} Target: bulat okudzhava\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [00:02<00:07,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'saxophone', 'guitar', 'voice'} Target: guitar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [00:02<00:07,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'tamer hosny', 'julio iglesias', 'julia volkova'} Target: julio iglesias\n",
      "Predicted: {'science fiction writer', 'essayist', 'writer'} Target: playwright\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:03<00:06,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'ivan andreyevich krylov', 'j. m. coetzeeeeeeeeeee', 'vladislav krapivin'} Target: d. h. lawrence\n",
      "Predicted: {'pop music', 'rhythm and blues', 'contemporary r&b'} Target: hard rock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [00:03<00:06,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julio iglesias', 'julia volkova'} Target: myles kennedy\n",
      "Predicted: {'film actor', 'film director', 'film producer'} Target: producer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:03<00:05,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'tamer hosny', 'jimmy fallon', 'neil patrick harris'} Target: j. j. abrams\n",
      "Predicted: {'united states of america', 'egypt', 'sri lanka'} Target: thailand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [00:03<00:04,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {\"people's republic of china\", 'taiwan', 'united states of america'} Target: malaysia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:04<00:04,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'african union - united nations hybrid operation in darfur', 'organisation for the prohibition of chemical weapons', 'international telecommunication union'} Target: international finance corporation\n",
      "Predicted: {'senegal', 'egypt', 'sri lanka'} Target: madagascar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [00:04<00:05,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'musical composition', 'poetry', 'performing arts'} Target: performing arts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:04<00:05,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'j. m. coetzeeeeeeeeee', 'j. m. coetzeeeeeeeeeee', 't. s. eliot'} Target: serge gainsbourg\n",
      "Predicted: {'emi', 'columbia records', 'rca records'} Target: hollywood records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:05<00:04,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'julio iglesias', 'julia volkova', 'idina menzel'} Target: kevin jonas\n",
      "Predicted: {'warner bros. records', 'columbia records', 'rca records'} Target: warner music group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [00:05<00:04,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'joe walsh', 'julia volkova', 'idina menzel'} Target: kenny rogers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [00:05<00:04,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'russian academy of sciences', 'societe philomathique de paris', 'saint petersburg academy of sciences'} Target: german academy of sciences leopoldina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:06<00:03,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'george porter, baron porter of luddenham', 'carl friedrich von weizsacker', 'heinrich wilhelm gottfried von waldeyer-hartz'} Target: victor ambartsumian\n",
      "Predicted: {'science fiction writer', 'mathematician', 'physicist'} Target: chemist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:06<00:03,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'george porter, baron porter of luddenham', 'henry louis le chatelier', 'joseph-louis lagrange'} Target: james bryant conant\n",
      "Predicted: {'pedagogue', 'physicist', 'linguist'} Target: philosopher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:06<00:02,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'thomas aquinas', 'euclides da cunha', 'wilhelm von humboldt'} Target: franz miklosich\n",
      "Predicted: {'taiwan', 'germany', 'united states of america'} Target: indonesia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [00:07<00:02,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'syria', 'taiwan', 'sri lanka'} Target: bosnia and herzegovina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [00:07<00:02,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'african americans', 'ashkenazi jews', 'american jews'} Target: african americans\n",
      "Predicted: {'jimmy fallon', 'taylor momsen', 'john lennon'} Target: charlie wilson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:07<00:01,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'international centre for settlement of investment disputes', 'organisation for the prohibition of chemical weapons', 'international telecommunication union'} Target: universal postal union\n",
      "Predicted: {'guinea-bissau', 'egypt', 'sri lanka'} Target: luxembourg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [00:07<00:01,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'pedagogue', 'physicist', 'university teacher'} Target: musicologist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:08<00:01,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'ernst mayr', 'euclides da cunha', 'adriano celentano'} Target: max weber\n",
      "Predicted: {'pop music', 'rock music', 'rhythm and blues'} Target: disco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [00:08<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julia volkova', 'john lennon'} Target: valery leontiev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [00:08<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'united kingdom of great britain and ireland', 'kingdom of italy', 'united states of america'} Target: kingdom of italy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:09<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'francois-rene de chateaubriand', 'jean-jacques rousseau', 'euclides da cunha'} Target: augusto righi\n",
      "Predicted: {'organisation for economic cooperation and development', 'organisation for the prohibition of chemical weapons', 'international telecommunication union'} Target: international bank for reconstruction and development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [00:09<00:00,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'senegal', 'egypt', 'sri lanka'} Target: serbia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:09<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'sri lanka', 'united kingdom of great britain and ireland', 'united states of america'} Target: mexico\n",
      "Predicted: {'eugene ionesco', 'euclides da cunha', 'heinrich schliemann'} Target: gloria trevi\n",
      "0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# id = 100\n",
    "scorer_function = getBeamOutput \n",
    "# scorer_function = getGreedyOutput \n",
    "num_points = 50\n",
    "correct = 0\n",
    "for id in tqdm(range(0, num_points)):\n",
    "    data_point = data[id]\n",
    "    input, target = data_point.split('\\t')\n",
    "    predicted = set(scorer_function(model, tokenizer, input))\n",
    "    print(\"Predicted:\", predicted, \"Target:\", target)\n",
    "    if target in predicted:\n",
    "        correct += 1\n",
    "print(correct/num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80de7387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     3,  2160,    17,  1273, 22269,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d = data[0]\n",
    "# inputs, outputs = d.split('\\t')\n",
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "outputs = 'british english'\n",
    "x = tokenizer([inputs], return_tensors=\"pt\", add_special_tokens=True)\n",
    "input_ids = x.input_ids.to(model.device)\n",
    "attention_mask = x.attention_mask.to(model.device)\n",
    "labels = tokenizer([outputs], return_tensors=\"pt\").input_ids.to(model.device)\n",
    "target_tokens = tokenizer(outputs, return_tensors=\"pt\").input_ids[0]\n",
    "\n",
    "decoder_start_token_id = 0\n",
    "decoder_input_ids = (\n",
    "            torch.ones((input_ids.shape[0], 1), dtype=torch.long, device=input_ids.device) * decoder_start_token_id\n",
    "        )\n",
    "decoder_input_ids = torch.cat((decoder_input_ids,labels), dim=-1)\n",
    "decoder_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf70b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(input_ids = input_ids,\n",
    "         attention_mask=attention_mask,\n",
    "         labels=labels)\n",
    "\n",
    "# x = model(input_ids = input_ids,\n",
    "#          attention_mask=attention_mask,\n",
    "#          decoder_input_ids = decoder_input_ids)\n",
    "\n",
    "logits = x.logits[0]\n",
    "probs = torch.log_softmax(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "746a1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_file = 'data/{}/entity_strings.txt'.format(dataset_name)\n",
    "with open(entities_file) as f:\n",
    "    entities_strings = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "735a6f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f149351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def getScore(model, inputs, outputs):\n",
    "    x = tokenizer([inputs], return_tensors=\"pt\", add_special_tokens=True)\n",
    "    input_ids = x.input_ids.to(model.device)\n",
    "    labels = tokenizer([outputs], return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    target_tokens = labels[0]\n",
    "    model_output = model(input_ids = input_ids,\n",
    "             attention_mask=attention_mask,\n",
    "             labels=labels)\n",
    "    logits = model_output.logits[0]\n",
    "    probs = torch.log_softmax(logits, 1)\n",
    "    score = 0.0\n",
    "    for i, id in enumerate(target_tokens):\n",
    "        s = probs[i][id]\n",
    "        score += s\n",
    "    return score\n",
    "\n",
    "def getBatchScore(model, inputs, entities, batch_size=100):\n",
    "    scores = []\n",
    "    input_ids = tokenizer(inputs, return_tensors=\"pt\", add_special_tokens=True).input_ids.to(model.device)\n",
    "    for start_id in range(0, len(entities), batch_size):\n",
    "        entity_batch = entities[start_id:start_id + batch_size]\n",
    "        cur_batch_size = len(entity_batch)\n",
    "        batch_input_ids = input_ids.expand(cur_batch_size, -1)\n",
    "        labels = tokenizer(entity_batch, \n",
    "                           return_tensors=\"pt\",\n",
    "                           padding=True).input_ids.to(model.device)\n",
    "        model_output = model(input_ids = batch_input_ids,\n",
    "                         labels=labels)\n",
    "        logits = model_output.logits\n",
    "        probs = torch.log_softmax(logits, -1)\n",
    "        for i in range(cur_batch_size):\n",
    "            token_probs = probs[i]\n",
    "            entity_tokenized = labels[i]\n",
    "            entity_score = 0.0\n",
    "            for position, token_id in enumerate(entity_tokenized):\n",
    "                entity_score += token_probs[position][token_id]\n",
    "                if token_id == 1:\n",
    "                    break\n",
    "            scores.append(entity_score.item())\n",
    "    return np.array(scores)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae6c284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "inputs = data[0].split('\\t')[0]\n",
    "scores = getBatchScore(model, inputs, entities_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f7644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 162/3656 [06:55<2:31:33,  2.60s/it]"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for d in tqdm(data):\n",
    "    inputs = d.split('\\t')[0]\n",
    "    scores = getBatchScore(model, inputs, entities_strings)\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d0eb93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'russia'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = (-scores).argsort()[:10]\n",
    "entities_strings[top[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b78c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_np = np.array(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f238739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fname = 'codex-s_small_1gpu_20000_test_scores.pickle'\n",
    "pickle.dump(all_scores_np, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "f5b90668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16]) torch.Size([3, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9689,  9891,    10,  2876,    63, 21979,  1820,  8024, 11518,     6,\n",
       "          1545,     6,    42,  3814,  1820,     1],\n",
       "        [ 9689,  9891,    10,  2876,    63, 21979,  1820,  8024, 11518,     6,\n",
       "          1545,     6,    42,  3814,  1820,     1],\n",
       "        [ 9689,  9891,    10,  2876,    63, 21979,  1820,  8024, 11518,     6,\n",
       "          1545,     6,    42,  3814,  1820,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "input_ids = tokenizer(inputs, return_tensors=\"pt\", add_special_tokens=True).input_ids.to(model.device)\n",
    "input_ids.shape\n",
    "new_tensor = input_ids.expand(3,-1)\n",
    "print(input_ids.shape, new_tensor.shape)\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f16a00e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0665, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "outputs = 'english'\n",
    "getScore(model, inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "678ae2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17050/17050 [06:38<00:00, 42.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_score_entity = ''\n",
    "max_score = -9999999.\n",
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "scores = np.array([])\n",
    "for e in tqdm(entities_strings):\n",
    "    outputs = e\n",
    "    s = getScore(model, inputs, outputs)\n",
    "    scores = np.append(scores, s.detach().cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2bde2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = (-scores).argsort()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97227722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'english'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_strings[top[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "be5bfcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.565360069274902\n"
     ]
    }
   ],
   "source": [
    "score = 0.0\n",
    "for i, id in enumerate(target_tokens):\n",
    "    s = probs[i][id]\n",
    "    score += s\n",
    "# score = torch.max(logits[0])\n",
    "print(score.item())\n",
    "# average_score_per_token = score.item()/(len(target_tokens))\n",
    "# print(average_score_per_token, len(target_tokens))\n",
    "# score = score.item()\n",
    "# print(score/len(target_tokens), score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "07686ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.8634,   4.0730,  -2.0617,  11.3171, -12.6902,  -0.2787,  -0.1332,\n",
      "          1.3992,   4.9949,   1.2909], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor(15.8887, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(logits[0][:10])\n",
    "print(torch.max(logits[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "612387f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁english']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([torch.argmax(logits[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33598803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import T5_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89cfc6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20622/20622 [00:00<00:00, 840393.08it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = T5_Dataset('test', dataset_name='codex-m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf51206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_accelerate import removePadding, eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8985d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 200\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b75ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:59<00:00,  1.74batches/s]\n"
     ]
    }
   ],
   "source": [
    "acc = eval(model, valid_dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03845319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10876733585491223"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de02c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = tokenizer(\"international development association\", return_tensors=\"pt\").input_ids[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033a792c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1038,  606, 6028,    1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "541e9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = outputs[0][1:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e357e189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1038,  2137,    21, 20532,    11,   606,     1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb42b5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual == predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a0b725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1038,  606, 6028,    1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f946f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

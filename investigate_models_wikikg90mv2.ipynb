{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "armed-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model args\n",
      "Namespace(batch_size=80, dataset='web_questions', epochs=50, force_lr=1, hf_dataset=1, hops=1, large_dataset=0, learning_rate=0.0005, load_checkpoint='wikikg90mv2_small/1020000.pt', loss_steps=250, max_checkpoints=5, max_input_sequence_length=40, max_output_sequence_length=30, model_size='t5-small', num_workers=4, optimizer='adafactor', pad_to_max=False, relation_prediction=0, resume=None, save_prefix='wq_small', save_steps=500, start_steps=0, task='qa', tokenizer='t5', use_lm_pretraining=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████▎                                            | 81471/376358 [00:00<00:00, 814704.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is 32100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 376358/376358 [00:00<00:00, 901225.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from utils_accelerate import *\n",
    "import sentencepiece as spm\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "dataset_name = 'wikidata5m'\n",
    "# input = \"predict tail: barack obama | position_held |\"small)1\n",
    "# input = \"translate English to German: How are you doing?\"\n",
    "\n",
    "# model = T5ForConditionalGeneration.from_pretrained('models/codex_m_accelerate_1gpu.pt')\n",
    "# checkpoint_location = 'models/codex_m_accelerate_1gpu/115000.pt'\n",
    "\n",
    "# checkpoint_location = 'models/codex-s_small_1gpu/20000.pt'\n",
    "# checkpoint_location = 'models/codex-m_tiny/70000.pt'\n",
    "# checkpoint_location = 'models/codex-m_small_6gpu/45000.pt'\n",
    "checkpoint_location = 'models/wikikg90mv2_small/920000.pt'\n",
    "checkpoint_location = 'models/wq_small/5500.pt'\n",
    "model = load_accelerator_model(checkpoint_location, only_model=True)\n",
    "model.eval()\n",
    "# model.cpu()\n",
    "# model.cuda()\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740f669a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8cc48771-9431-4283-8c7f-34078b1dbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '/scratche/home/apoorv/hf_model_repos/kgt5-wikikg90mv2'\n",
    "model.save_pretrained(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f12a43-0991-4c88-bb21-a18ea1c0ce87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/scratche/home/apoorv/hf_model_repos/kgt5-wikikg90mv2/tokenizer_config.json',\n",
       " '/scratche/home/apoorv/hf_model_repos/kgt5-wikikg90mv2/special_tokens_map.json',\n",
       " '/scratche/home/apoorv/hf_model_repos/kgt5-wikikg90mv2/spiece.model',\n",
       " '/scratche/home/apoorv/hf_model_repos/kgt5-wikikg90mv2/added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a6462444-e2dd-4306-aecd-3ec7182e7175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 18:23:40.395501: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-11 18:23:40.434086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-11 18:23:40.796449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-02-11 18:23:40.797731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-02-11 18:23:40.798989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-02-11 18:23:40.807215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-02-11 18:23:40.808734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-02-11 18:23:40.817177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:0c:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-02-11 18:23:40.820854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:0d:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-02-11 18:23:40.826470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-02-11 18:23:40.826550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-02-11 18:23:40.885198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-02-11 18:23:40.885245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-02-11 18:23:40.910413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-11 18:23:40.919022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-11 18:23:41.004635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-11 18:23:41.020415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-02-11 18:23:41.021315: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-02-11 18:23:41.021347: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-11 18:23:41.023007: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-11 18:23:41.027448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-11 18:23:41.027469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2022-02-11 18:23:41.027478: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-11 18:23:41.051782: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFT5ForConditionalGeneration: ['decoder.embed_tokens.weight', 'lm_head.weight', 'encoder.embed_tokens.weight']\n",
      "- This IS expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# save in tensorflow format\n",
    "from transformers import TFT5ForConditionalGeneration\n",
    "location = '/scratche/home/apoorv/hf_model_repos/kgt5-wikikg90mv2'\n",
    "tf_model = TFT5ForConditionalGeneration.from_pretrained(location, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "68d15375-c3d9-4b0f-8cfa-190f30bf7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.save_pretrained(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7c4740cc-06ba-4bef-8155-8352215684d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /scratche/home/apoorv/hf_model_repos/kgt5-wikikg90mv2 were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model2 = AutoModel.from_pretrained(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f035b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "# config = T5Config().from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f6aed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8cf10893-6212-4dbb-ae05-6d42e9327e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedyPredict(input, model, tokenizer):\n",
    "    input_ids = tokenizer([input], return_tensors=\"pt\").input_ids\n",
    "    out_tokens = model.generate(input_ids)\n",
    "    out_str = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\n",
    "    return out_str[0]\n",
    "\n",
    "def greedyPredictBatch(input, model, tokenizer):\n",
    "    tokenized = tokenizer(input, return_tensors=\"pt\")\n",
    "    out_tokens = model.generate(**tokenized)\n",
    "    out_str = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\n",
    "    return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "95f37628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Achintya'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = \"T. C. Achintya\"\n",
    "relation = \"family name\"\n",
    "input = subject + \"| \" + relation\n",
    "# input = \"Queen Victoria| related to\"\n",
    "# input = \"Tokyo Olympics 2016| host country\"\n",
    "out = greedyPredict(input, model, tokenizer)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fac784ff-fc07-42b8-9ab9-36ca836f652f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jazmyn Bieber'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"predict answer: what is the name of justin bieber brother?\"\n",
    "out = greedyPredict(input, model, tokenizer)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08023352-0ac0-4fca-971e-00ce05924381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q4234279']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedyPredictBatch([\"Q42342344| follows\"], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2bfb909-b276-42da-a796-5d746df7dd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74c02912abf4b18af35778a8c298d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1320.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04984ff87b8a48f2abe74de32ad48476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f7270b596f4cde9a6cc22d7fde9c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1786.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f29f8fb42444abe836189cf6db806b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1857.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ce6ebc4c774facb2951af596668994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=242083771.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"apoorvumang/kgt5-wikikg90mv2\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"apoorvumang/kgt5-wikikg90mv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f930dc63-28c1-40a9-8f36-ddef1a1350c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ab5a1390474394801d31ec6203c69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1659.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a801d1675948ecb4cede80d69362e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1066.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset web_questions/default (download: 1.21 MiB, generated: 804.26 KiB, post-processed: Unknown size, total: 2.00 MiB) to /home/apoorv/.cache/huggingface/datasets/web_questions/default/1.0.0/e6742cc64f6652db0c52cb07b5414e3c001512bf5bde7aa5587353c31db1ed8b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a507a903dc44303a17e36659c983a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', layout=Layout(width='20px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c4075dedee4d2ab295ec02fb8fc1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', layout=Layout(width='20px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset web_questions downloaded and prepared to /home/apoorv/.cache/huggingface/datasets/web_questions/default/1.0.0/e6742cc64f6652db0c52cb07b5414e3c001512bf5bde7aa5587353c31db1ed8b. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# try datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"web_questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "af48402b-f34c-4402-927e-f24555e5046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': ['Jamaican Creole English Language', 'Jamaican English'],\n",
       " 'question': 'what does jamaican people speak?',\n",
       " 'url': 'http://www.freebase.com/view/en/jamaica'}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d857774e-d7dc-40fb-8d5f-81e8ef858a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def remove_punc(s):\n",
    "    res = re.sub(r'[^\\w\\s]', '', s)\n",
    "    return res\n",
    "\n",
    "def normalize(s):\n",
    "    s = s.replace('\\t', ' ')\n",
    "    s = s.replace('|', '.')\n",
    "    s = unicodedata.normalize('NFKC', s)\n",
    "    return s\n",
    "\n",
    "def normalize_and_remove_punc(s):\n",
    "    return remove_punc(normalize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "83a64d1c-d5e2-4f8e-8c7c-72e81431d6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict answer: where did paula deen go to school?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Miami High School', ['Albany High School'])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 529\n",
    "question = 'predict answer: ' + normalize(dataset['test'][id]['question'])\n",
    "print(question)\n",
    "out = greedyPredict(question, model, tokenizer)\n",
    "true_answers = dataset['test'][id]['answers']\n",
    "out, true_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "96fdff74-f500-443c-b00e-0004bf53cd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad59904fedc4354bed2f3c6c6aebffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2032.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "test_predictions = []\n",
    "for dp in tqdm(dataset['test']):\n",
    "    question = 'predict answer: ' + normalize(dp['question'])\n",
    "    out = greedyPredict(question, model, tokenizer)\n",
    "    test_predictions.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b33fd3f4-c581-45d3-9aac-c1887d1c3828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515, 0.2534448818897638)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for i in range(len(test_predictions)):\n",
    "    pred = remove_punc(test_predictions[i].lower())\n",
    "    true_ans = [normalize_and_remove_punc(s.lower()) for s in dataset['test'][i]['answers']]\n",
    "    if pred in true_ans:\n",
    "        num_correct += 1\n",
    "num_correct, num_correct/len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89e4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5470a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model.sample(input_ids)\n",
    "from transformers import (\n",
    "    LogitsProcessorList,\n",
    "    MinLengthLogitsProcessor,\n",
    "    BeamSearchScorer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e68cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = 'data/codex-m/test.txt'\n",
    "fname = 'data/{}/test.txt'.format(dataset_name)\n",
    "f = open(fname, 'r')\n",
    "data = []\n",
    "for line in f:\n",
    "    data.append(line.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdcdb004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10642"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247d8097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predict tail: walter harris (artist) | country of citizenship |\\tcanada'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c2394bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_wd_id_dict(filename):\n",
    "    out = {}\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        line = line.split('\\t')\n",
    "        out[line[1]] = line[0]\n",
    "    return out\n",
    "\n",
    "e2wdid = get_entity_wd_id_dict('data/wikidata5m/aliases.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240598bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# data_point = 'predict tail: novalis | occupation |    philosopher'\n",
    "id = 2\n",
    "data_point = data[id]\n",
    "encoder_input_str, target = data_point.split('\\t')\n",
    "encoder_input_str = [encoder_input_str]\n",
    "encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "num_beams = 2\n",
    "num_predictions = 2\n",
    "input_ids = torch.ones((len(encoder_input_str) * num_beams, 1), device=model.device, dtype=torch.long)\n",
    "input_ids = input_ids * model.config.decoder_start_token_id\n",
    "model_kwargs = {\n",
    "    \"encoder_outputs\": model.get_encoder()(encoder_input_ids.repeat_interleave(num_beams, dim=0), return_dict=True)\n",
    "}\n",
    "beam_scorer = BeamSearchScorer(\n",
    "    batch_size=len(encoder_input_str),\n",
    "    max_length=model.config.max_length,\n",
    "    num_beams=num_beams,\n",
    "    device=model.device,\n",
    "    num_beam_hyps_to_keep=num_predictions,\n",
    "    length_penalty=0.3\n",
    ")\n",
    "logits_processor = LogitsProcessorList([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3dfe273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict tail: mon oncle benjamin (movie) | original language of film or tv show |\n"
     ]
    }
   ],
   "source": [
    "input = 'predict tail: mon oncle benjamin (movie) | original language of film or tv show |'\n",
    "encoder_input_str = [input]\n",
    "encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "print(encoder_input_str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "eca081b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "languefrancaise\n"
     ]
    }
   ],
   "source": [
    "# outputs = model.beam_search(input_ids, beam_scorer, logits_processor=logits_processor, **model_kwargs)\n",
    "# print(\"Beam:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "outputs = model.generate(encoder_input_ids).tolist()[0]\n",
    "outputs = outputs[1:]\n",
    "outputs = outputs[:outputs.index(2)]\n",
    "print(tokenizer.sp.decode(outputs))\n",
    "# print('Target:', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3d685399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5221150'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2wdid['dante alighieri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b89c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdid2e = {v:k for k, v in e2wdid.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "89bcdafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'original language of film or tv show'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdid2e['P364']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63ef0801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m/s/doculation/doc/docantc'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sp.decode(outputs.tolist()[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf747a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d77eafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGreedyOutput(model, tokenizer, encoder_input_str):\n",
    "    encoder_input_str = [encoder_input_str]\n",
    "    encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(encoder_input_ids)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c64be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeamOutput(model, tokenizer, encoder_input_str, num_beams=10, \n",
    "                  num_predictions=3, length_penalty=1.0):\n",
    "    encoder_input_str = [encoder_input_str]\n",
    "    encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "#     encoder_input_ids = tokenizer(encoder_input_str, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\").input_ids\n",
    "    input_ids = torch.ones((len(encoder_input_str) * num_beams, 1), device=model.device, dtype=torch.long)\n",
    "    input_ids = input_ids * model.config.decoder_start_token_id\n",
    "    model_kwargs = {\n",
    "        \"encoder_outputs\": model.get_encoder()(encoder_input_ids.repeat_interleave(num_beams, dim=0), return_dict=True)\n",
    "    }\n",
    "    beam_scorer = BeamSearchScorer(\n",
    "        batch_size=len(encoder_input_str),\n",
    "        max_length=model.config.max_length,\n",
    "        num_beams=num_beams,\n",
    "        device=model.device,\n",
    "        num_beam_hyps_to_keep=num_predictions,\n",
    "        length_penalty=length_penalty\n",
    "    )\n",
    "    logits_processor = LogitsProcessorList([])\n",
    "    outputs = model.beam_search(input_ids, beam_scorer, logits_processor=logits_processor, **model_kwargs)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23eef50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3944fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:16,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'france', 'united kingdom of great britain and ireland', 'kingdom of italy'} Target: france\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:00<00:14,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'jean-baptiste dumas', 'francois-rene de chateaubriand', 'jean-baptiste biot'} Target: gaspard monge\n",
      "Predicted: {'film actor', 'singer-songwriter', 'film producer'} Target: mandolinist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:01<00:10,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julio iglesias', 'julia volkova'} Target: leon russell\n",
      "Predicted: {'film actor', 'singer-songwriter', 'philanthropist'} Target: singer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:01<00:08,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julia volkova', 'idina menzel'} Target: mos def\n",
      "Predicted: {'short story', 'symphony', 'novel'} Target: prose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:01<00:09,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'ivan andreyevich krylov', 'j. m. coetzeeeeeeeeeee', 'vladislav krapivin'} Target: max frisch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:02<00:09,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'saint petersburg', 'russian soviet federative socialist republic', 'moscow'} Target: soviet union\n",
      "Predicted: {'russian academy of sciences', 'academy of sciences of the ussr', 'saint petersburg academy of sciences'} Target: bulat okudzhava\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:02<00:07,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'saxophone', 'guitar', 'voice'} Target: guitar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:02<00:07,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'tamer hosny', 'julio iglesias', 'julia volkova'} Target: julio iglesias\n",
      "Predicted: {'science fiction writer', 'essayist', 'writer'} Target: playwright\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:03<00:06,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'ivan andreyevich krylov', 'j. m. coetzeeeeeeeeeee', 'vladislav krapivin'} Target: d. h. lawrence\n",
      "Predicted: {'pop music', 'rhythm and blues', 'contemporary r&b'} Target: hard rock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:03<00:06,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julio iglesias', 'julia volkova'} Target: myles kennedy\n",
      "Predicted: {'film actor', 'film director', 'film producer'} Target: producer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:03<00:05,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'tamer hosny', 'jimmy fallon', 'neil patrick harris'} Target: j. j. abrams\n",
      "Predicted: {'united states of america', 'egypt', 'sri lanka'} Target: thailand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:03<00:04,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {\"people's republic of china\", 'taiwan', 'united states of america'} Target: malaysia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:04<00:04,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'african union - united nations hybrid operation in darfur', 'organisation for the prohibition of chemical weapons', 'international telecommunication union'} Target: international finance corporation\n",
      "Predicted: {'senegal', 'egypt', 'sri lanka'} Target: madagascar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:04<00:05,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'musical composition', 'poetry', 'performing arts'} Target: performing arts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:04<00:05,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'j. m. coetzeeeeeeeeee', 'j. m. coetzeeeeeeeeeee', 't. s. eliot'} Target: serge gainsbourg\n",
      "Predicted: {'emi', 'columbia records', 'rca records'} Target: hollywood records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:05<00:04,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'julio iglesias', 'julia volkova', 'idina menzel'} Target: kevin jonas\n",
      "Predicted: {'warner bros. records', 'columbia records', 'rca records'} Target: warner music group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:05<00:04,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'joe walsh', 'julia volkova', 'idina menzel'} Target: kenny rogers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:05<00:04,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'russian academy of sciences', 'societe philomathique de paris', 'saint petersburg academy of sciences'} Target: german academy of sciences leopoldina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:06<00:03,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'george porter, baron porter of luddenham', 'carl friedrich von weizsacker', 'heinrich wilhelm gottfried von waldeyer-hartz'} Target: victor ambartsumian\n",
      "Predicted: {'science fiction writer', 'mathematician', 'physicist'} Target: chemist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:06<00:03,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'george porter, baron porter of luddenham', 'henry louis le chatelier', 'joseph-louis lagrange'} Target: james bryant conant\n",
      "Predicted: {'pedagogue', 'physicist', 'linguist'} Target: philosopher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:06<00:02,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'thomas aquinas', 'euclides da cunha', 'wilhelm von humboldt'} Target: franz miklosich\n",
      "Predicted: {'taiwan', 'germany', 'united states of america'} Target: indonesia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:07<00:02,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'syria', 'taiwan', 'sri lanka'} Target: bosnia and herzegovina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [00:07<00:02,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'african americans', 'ashkenazi jews', 'american jews'} Target: african americans\n",
      "Predicted: {'jimmy fallon', 'taylor momsen', 'john lennon'} Target: charlie wilson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:07<00:01,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'international centre for settlement of investment disputes', 'organisation for the prohibition of chemical weapons', 'international telecommunication union'} Target: universal postal union\n",
      "Predicted: {'guinea-bissau', 'egypt', 'sri lanka'} Target: luxembourg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:07<00:01,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'pedagogue', 'physicist', 'university teacher'} Target: musicologist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:08<00:01,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'ernst mayr', 'euclides da cunha', 'adriano celentano'} Target: max weber\n",
      "Predicted: {'pop music', 'rock music', 'rhythm and blues'} Target: disco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:08<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julia volkova', 'john lennon'} Target: valery leontiev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:08<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'united kingdom of great britain and ireland', 'kingdom of italy', 'united states of america'} Target: kingdom of italy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:09<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'francois-rene de chateaubriand', 'jean-jacques rousseau', 'euclides da cunha'} Target: augusto righi\n",
      "Predicted: {'organisation for economic cooperation and development', 'organisation for the prohibition of chemical weapons', 'international telecommunication union'} Target: international bank for reconstruction and development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [00:09<00:00,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'senegal', 'egypt', 'sri lanka'} Target: serbia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:09<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'sri lanka', 'united kingdom of great britain and ireland', 'united states of america'} Target: mexico\n",
      "Predicted: {'eugene ionesco', 'euclides da cunha', 'heinrich schliemann'} Target: gloria trevi\n",
      "0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# id = 100\n",
    "scorer_function = getBeamOutput \n",
    "# scorer_function = getGreedyOutput \n",
    "num_points = 50\n",
    "correct = 0\n",
    "for id in tqdm(range(0, num_points)):\n",
    "    data_point = data[id]\n",
    "    input, target = data_point.split('\\t')\n",
    "    predicted = set(scorer_function(model, tokenizer, input))\n",
    "    print(\"Predicted:\", predicted, \"Target:\", target)\n",
    "    if target in predicted:\n",
    "        correct += 1\n",
    "print(correct/num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80de7387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     3,  2160,    17,  1273, 22269,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d = data[0]\n",
    "# inputs, outputs = d.split('\\t')\n",
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "outputs = 'british english'\n",
    "x = tokenizer([inputs], return_tensors=\"pt\", add_special_tokens=True)\n",
    "input_ids = x.input_ids.to(model.device)\n",
    "attention_mask = x.attention_mask.to(model.device)\n",
    "labels = tokenizer([outputs], return_tensors=\"pt\").input_ids.to(model.device)\n",
    "target_tokens = tokenizer(outputs, return_tensors=\"pt\").input_ids[0]\n",
    "\n",
    "decoder_start_token_id = 0\n",
    "decoder_input_ids = (\n",
    "            torch.ones((input_ids.shape[0], 1), dtype=torch.long, device=input_ids.device) * decoder_start_token_id\n",
    "        )\n",
    "decoder_input_ids = torch.cat((decoder_input_ids,labels), dim=-1)\n",
    "decoder_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf70b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(input_ids = input_ids,\n",
    "         attention_mask=attention_mask,\n",
    "         labels=labels)\n",
    "\n",
    "# x = model(input_ids = input_ids,\n",
    "#          attention_mask=attention_mask,\n",
    "#          decoder_input_ids = decoder_input_ids)\n",
    "\n",
    "logits = x.logits[0]\n",
    "probs = torch.log_softmax(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "746a1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_file = 'data/{}/entity_strings.txt'.format(dataset_name)\n",
    "with open(entities_file) as f:\n",
    "    entities_strings = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "735a6f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f149351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def getScore(model, inputs, outputs):\n",
    "    x = tokenizer([inputs], return_tensors=\"pt\", add_special_tokens=True)\n",
    "    input_ids = x.input_ids.to(model.device)\n",
    "    labels = tokenizer([outputs], return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    target_tokens = labels[0]\n",
    "    model_output = model(input_ids = input_ids,\n",
    "             attention_mask=attention_mask,\n",
    "             labels=labels)\n",
    "    logits = model_output.logits[0]\n",
    "    probs = torch.log_softmax(logits, 1)\n",
    "    score = 0.0\n",
    "    for i, id in enumerate(target_tokens):\n",
    "        s = probs[i][id]\n",
    "        score += s\n",
    "    return score\n",
    "\n",
    "def getBatchScore(model, inputs, entities, batch_size=100):\n",
    "    scores = []\n",
    "    input_ids = tokenizer(inputs, return_tensors=\"pt\", add_special_tokens=True).input_ids.to(model.device)\n",
    "    for start_id in range(0, len(entities), batch_size):\n",
    "        entity_batch = entities[start_id:start_id + batch_size]\n",
    "        cur_batch_size = len(entity_batch)\n",
    "        batch_input_ids = input_ids.expand(cur_batch_size, -1)\n",
    "        labels = tokenizer(entity_batch, \n",
    "                           return_tensors=\"pt\",\n",
    "                           padding=True).input_ids.to(model.device)\n",
    "        model_output = model(input_ids = batch_input_ids,\n",
    "                         labels=labels)\n",
    "        logits = model_output.logits\n",
    "        probs = torch.log_softmax(logits, -1)\n",
    "        for i in range(cur_batch_size):\n",
    "            token_probs = probs[i]\n",
    "            entity_tokenized = labels[i]\n",
    "            entity_score = 0.0\n",
    "            for position, token_id in enumerate(entity_tokenized):\n",
    "                entity_score += token_probs[position][token_id]\n",
    "                if token_id == 1:\n",
    "                    break\n",
    "            scores.append(entity_score.item())\n",
    "    return np.array(scores)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae6c284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "inputs = data[0].split('\\t')[0]\n",
    "scores = getBatchScore(model, inputs, entities_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f7644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 162/3656 [06:55<2:31:33,  2.60s/it]"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for d in tqdm(data):\n",
    "    inputs = d.split('\\t')[0]\n",
    "    scores = getBatchScore(model, inputs, entities_strings)\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d0eb93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'russia'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = (-scores).argsort()[:10]\n",
    "entities_strings[top[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b78c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_np = np.array(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f238739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fname = 'codex-s_small_1gpu_20000_test_scores.pickle'\n",
    "pickle.dump(all_scores_np, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "f5b90668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16]) torch.Size([3, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9689,  9891,    10,  2876,    63, 21979,  1820,  8024, 11518,     6,\n",
       "          1545,     6,    42,  3814,  1820,     1],\n",
       "        [ 9689,  9891,    10,  2876,    63, 21979,  1820,  8024, 11518,     6,\n",
       "          1545,     6,    42,  3814,  1820,     1],\n",
       "        [ 9689,  9891,    10,  2876,    63, 21979,  1820,  8024, 11518,     6,\n",
       "          1545,     6,    42,  3814,  1820,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "input_ids = tokenizer(inputs, return_tensors=\"pt\", add_special_tokens=True).input_ids.to(model.device)\n",
    "input_ids.shape\n",
    "new_tensor = input_ids.expand(3,-1)\n",
    "print(input_ids.shape, new_tensor.shape)\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f16a00e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0665, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "outputs = 'english'\n",
    "getScore(model, inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "678ae2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17050/17050 [06:38<00:00, 42.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_score_entity = ''\n",
    "max_score = -9999999.\n",
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "scores = np.array([])\n",
    "for e in tqdm(entities_strings):\n",
    "    outputs = e\n",
    "    s = getScore(model, inputs, outputs)\n",
    "    scores = np.append(scores, s.detach().cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2bde2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = (-scores).argsort()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97227722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'english'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_strings[top[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "be5bfcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.565360069274902\n"
     ]
    }
   ],
   "source": [
    "score = 0.0\n",
    "for i, id in enumerate(target_tokens):\n",
    "    s = probs[i][id]\n",
    "    score += s\n",
    "# score = torch.max(logits[0])\n",
    "print(score.item())\n",
    "# average_score_per_token = score.item()/(len(target_tokens))\n",
    "# print(average_score_per_token, len(target_tokens))\n",
    "# score = score.item()\n",
    "# print(score/len(target_tokens), score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "07686ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.8634,   4.0730,  -2.0617,  11.3171, -12.6902,  -0.2787,  -0.1332,\n",
      "          1.3992,   4.9949,   1.2909], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor(15.8887, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(logits[0][:10])\n",
    "print(torch.max(logits[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "612387f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁english']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([torch.argmax(logits[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33598803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import T5_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89cfc6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20622/20622 [00:00<00:00, 840393.08it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = T5_Dataset('test', dataset_name='codex-m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf51206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_accelerate import removePadding, eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8985d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 200\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b75ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:59<00:00,  1.74batches/s]\n"
     ]
    }
   ],
   "source": [
    "acc = eval(model, valid_dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03845319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10876733585491223"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de02c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = tokenizer(\"international development association\", return_tensors=\"pt\").input_ids[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033a792c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1038,  606, 6028,    1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "541e9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = outputs[0][1:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e357e189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1038,  2137,    21, 20532,    11,   606,     1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb42b5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual == predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a0b725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1038,  606, 6028,    1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f946f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "armed-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model args\n",
      "Namespace(batch_size=64, dataset='wikikg90mv2', dropout=0.1, epochs=500, force_lr=0, hf_dataset=0, hops=1, large_dataset=1, learning_rate=None, load_checkpoint='wikikg90mv2_base_from_ptlm/1000000.pt', loss_steps=250, max_checkpoints=5, max_input_sequence_length=40, max_output_sequence_length=30, model_size='t5-base', num_workers=4, optimizer='adafactor', pad_to_max=False, relation_prediction=0, resume=None, save_prefix='wikikg90mv2_base_from_ptlm', save_steps=40000, start_steps=1000000, task='kgc', tokenizer='t5', use_lm_pretraining=0)\n",
      "Vocab size is 32100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from utils_accelerate import *\n",
    "import sentencepiece as spm\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "dataset_name = 'wikidata5m'\n",
    "# input = \"predict tail: barack obama | position_held |\"small)1\n",
    "# input = \"translate English to German: How are you doing?\"\n",
    "\n",
    "# model = T5ForConditionalGeneration.from_pretrained('models/codex_m_accelerate_1gpu.pt')\n",
    "# checkpoint_location = 'models/codex_m_accelerate_1gpu/115000.pt'\n",
    "\n",
    "# checkpoint_location = 'models/codex-s_small_1gpu/20000.pt'\n",
    "# checkpoint_location = 'models/codex-m_tiny/70000.pt'\n",
    "# checkpoint_location = 'models/codex-m_small_6gpu/45000.pt'\n",
    "# checkpoint_location = 'models/wikikg90mv2_small/2840000.pt'\n",
    "checkpoint_location = 'models/wikikg90mv2_base_from_ptlm/2120000.pt'\n",
    "model = load_accelerator_model(checkpoint_location, only_model=True)\n",
    "model.eval()\n",
    "# model.cpu()\n",
    "# model.cuda()\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e752f510-6f6c-4179-bd0e-c16b3493e9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222903552"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "740f669a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cc48771-9431-4283-8c7f-34078b1dbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location = '/scratche/home/apoorv/hf_model_repos/kgt5-wikikg90mv2'\n",
    "location = '/scratche/home/apoorv/hf_model_repos/kgt5-base-wikikg90mv2'\n",
    "model.save_pretrained(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72f12a43-0991-4c88-bb21-a18ea1c0ce87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/scratche/home/apoorv/hf_model_repos/kgt5-base-wikikg90mv2/tokenizer_config.json',\n",
       " '/scratche/home/apoorv/hf_model_repos/kgt5-base-wikikg90mv2/special_tokens_map.json',\n",
       " '/scratche/home/apoorv/hf_model_repos/kgt5-base-wikikg90mv2/spiece.model',\n",
       " '/scratche/home/apoorv/hf_model_repos/kgt5-base-wikikg90mv2/added_tokens.json')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6462444-e2dd-4306-aecd-3ec7182e7175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 18:30:52.600514: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-23 18:30:52.602881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-23 18:30:53.692547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-23 18:30:53.700477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-23 18:30:53.795350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-23 18:30:53.801912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-23 18:30:53.818833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-23 18:30:53.833663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:0c:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-23 18:30:53.835423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:0d:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-23 18:30:53.855849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-23 18:30:53.855933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-23 18:30:53.912914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-23 18:30:53.912968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-23 18:30:53.934574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-23 18:30:53.942436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-23 18:30:54.024861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-23 18:30:54.040567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-23 18:30:54.041360: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-23 18:30:54.041378: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-23 18:30:54.042035: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-23 18:30:54.045727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-23 18:30:54.045750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2022-03-23 18:30:54.045758: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-23 18:30:54.069969: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFT5ForConditionalGeneration: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight', 'lm_head.weight']\n",
      "- This IS expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# save in tensorflow format\n",
    "from transformers import TFT5ForConditionalGeneration\n",
    "# location = '/scratche/home/apoorv/hf_model_repos/kgt5-wikikg90mv2'\n",
    "location = '/scratche/home/apoorv/hf_model_repos/kgt5-base-wikikg90mv2'\n",
    "tf_model = TFT5ForConditionalGeneration.from_pretrained(location, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68d15375-c3d9-4b0f-8cfa-190f30bf7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.save_pretrained(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f035b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "# config = T5Config().from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f6aed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf10893-6212-4dbb-ae05-6d42e9327e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(ids, scores, pad_token_id):\n",
    "    \"\"\"get sequence scores from model.generate output\"\"\"\n",
    "    scores = torch.stack(scores, dim=1)\n",
    "    log_probs = torch.log_softmax(scores, dim=2)\n",
    "    # remove start token\n",
    "    ids = ids[:,1:]\n",
    "    # gather needed probs\n",
    "    x = ids.unsqueeze(-1).expand(log_probs.shape)\n",
    "    needed_logits = torch.gather(log_probs, 2, x)\n",
    "    final_logits = needed_logits[:, :, 0]\n",
    "    padded_mask = (ids == pad_token_id)\n",
    "    final_logits[padded_mask] = 0\n",
    "    final_scores = final_logits.sum(dim=-1)\n",
    "    return final_scores.cpu().detach().numpy()\n",
    "\n",
    "def greedyPredict(input, model, tokenizer):\n",
    "    input_ids = tokenizer([input], return_tensors=\"pt\").input_ids\n",
    "    out_tokens = model.generate(input_ids)\n",
    "    out_str = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\n",
    "    return out_str[0]\n",
    "\n",
    "def greedyPredictBatch(input, model, tokenizer):\n",
    "    tokenized = tokenizer(input, return_tensors=\"pt\")\n",
    "    out_tokens = model.generate(**tokenized)\n",
    "    out_str = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\n",
    "    return out_str\n",
    "\n",
    "def topkPredict(input, model, tokenizer, \n",
    "                num_predictions=5,\n",
    "                num_beams=1,\n",
    "                max_output_length=30):\n",
    "    tokenized = tokenizer(input, return_tensors=\"pt\")\n",
    "    out = model.generate(**tokenized,\n",
    "                        do_sample=True,\n",
    "                        num_return_sequences = num_predictions,\n",
    "                        num_beams = num_beams,\n",
    "                        eos_token_id = tokenizer.eos_token_id,\n",
    "                        pad_token_id = tokenizer.pad_token_id,\n",
    "                        output_scores = True,\n",
    "                        return_dict_in_generate=True,\n",
    "#                         length_penalty = args.length_penalty,\n",
    "                        max_length=max_output_length,)\n",
    "    out_tokens = out.sequences\n",
    "    out_str = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\n",
    "    out_scores = getScores(out_tokens, out.scores, tokenizer.pad_token_id)\n",
    "    \n",
    "    pair_list = [(x[0], x[1]) for x in zip(out_str, out_scores)]\n",
    "    sorted_pair_list = sorted(pair_list, key=lambda x:x[1], reverse=True)\n",
    "    return sorted_pair_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95f37628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basketball player'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = \"Joe Rogan\"\n",
    "relation = \"occupation\"\n",
    "input = subject + \"| \" + relation\n",
    "# input = \"Queen Victoria| related to\"\n",
    "# input = \"Tokyo Olympics 2016| host country\"\n",
    "out = greedyPredict(input, model, tokenizer)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58f840dc-17d4-42fa-8073-dba8d5577eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('botany', -3.9107945),\n",
       " ('law', -3.9145145),\n",
       " ('anthropology', -4.0013623),\n",
       " ('anthropology', -4.001363),\n",
       " ('Islamic culture', -6.2266335)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = \"Shah Rukh Khan\"\n",
    "relation = \"field of work\"\n",
    "input = subject + \"| \" + relation\n",
    "out = topkPredict(input, model, tokenizer)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "807a5a80-62bb-4d78-a892-f30b042f7e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['sequences', 'scores'])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fac784ff-fc07-42b8-9ab9-36ca836f652f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jaxon Bieber'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"predict answer: what is the name of justin bieber brother?\"\n",
    "out = greedyPredict(input, model, tokenizer)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "08023352-0ac0-4fca-971e-00ce05924381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q1234566']"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedyPredictBatch([\"Q1234567| follows\"], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2bfb909-b276-42da-a796-5d746df7dd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74c02912abf4b18af35778a8c298d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1320.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04984ff87b8a48f2abe74de32ad48476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f7270b596f4cde9a6cc22d7fde9c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1786.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f29f8fb42444abe836189cf6db806b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1857.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ce6ebc4c774facb2951af596668994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=242083771.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"apoorvumang/kgt5-wikikg90mv2\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"apoorvumang/kgt5-wikikg90mv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f930dc63-28c1-40a9-8f36-ddef1a1350c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset web_questions (/home/apoorv/.cache/huggingface/datasets/web_questions/default/1.0.0/e6742cc64f6652db0c52cb07b5414e3c001512bf5bde7aa5587353c31db1ed8b)\n"
     ]
    }
   ],
   "source": [
    "# try datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"web_questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af48402b-f34c-4402-927e-f24555e5046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': ['Jamaican Creole English Language', 'Jamaican English'],\n",
       " 'question': 'what does jamaican people speak?',\n",
       " 'url': 'http://www.freebase.com/view/en/jamaica'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d857774e-d7dc-40fb-8d5f-81e8ef858a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def remove_punc(s):\n",
    "    res = re.sub(r'[^\\w\\s]', '', s)\n",
    "    return res\n",
    "\n",
    "def normalize(s):\n",
    "    s = s.replace('\\t', ' ')\n",
    "    s = s.replace('|', '.')\n",
    "    s = unicodedata.normalize('NFKC', s)\n",
    "    return s\n",
    "\n",
    "def normalize_and_remove_punc(s):\n",
    "    return remove_punc(normalize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "409c5e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model args\n",
      "Namespace(batch_size=80, dataset='web_questions', dropout=0.2, epochs=200, force_lr=1, hf_dataset=1, hops=1, large_dataset=0, learning_rate=0.001, load_checkpoint=None, loss_steps=250, max_checkpoints=5, max_input_sequence_length=40, max_output_sequence_length=30, model_size='t5-small', num_workers=4, optimizer='adafactor', pad_to_max=False, relation_prediction=0, resume=None, save_prefix='wq_small_from_ptlm', save_steps=500, start_steps=0, task='qa', tokenizer='t5', use_lm_pretraining=1)\n",
      "Vocab size is 32100\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_location = 'models/wq_small/20000.pt'\n",
    "checkpoint_location = 'models/wq_small_from_ptlm/16000.pt'\n",
    "model = load_accelerator_model(checkpoint_location, only_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "83a64d1c-d5e2-4f8e-8c7c-72e81431d6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict answer: what does jamaican people speak?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('English Language', ['Jamaican Creole English Language', 'Jamaican English'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 0\n",
    "question = 'predict answer: ' + normalize(dataset['test'][id]['question'])\n",
    "print(question)\n",
    "out = greedyPredict(question, model, tokenizer)\n",
    "true_answers = dataset['test'][id]['answers']\n",
    "out, true_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96fdff74-f500-443c-b00e-0004bf53cd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd470c957a174f1a94ce1a9830e3aa18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2032.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "test_predictions = []\n",
    "for dp in tqdm(dataset['test']):\n",
    "    question = 'predict answer: ' + normalize(dp['question'])\n",
    "    out = greedyPredict(question, model, tokenizer)\n",
    "    test_predictions.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b33fd3f4-c581-45d3-9aac-c1887d1c3828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 0.2421259842519685)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for i in range(len(test_predictions)):\n",
    "    pred = remove_punc(test_predictions[i].lower())\n",
    "    true_ans = [normalize_and_remove_punc(s.lower()) for s in dataset['test'][i]['answers']]\n",
    "    if pred in true_ans:\n",
    "        num_correct += 1\n",
    "num_correct, num_correct/len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad10d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = T5Config().from_pretrained('t5-small', **kwargs)\n",
    "# test_model = T5ForConditionalGeneration(config)\n",
    "kwargs = {}\n",
    "kwargs['dropout_rate'] = 0.2\n",
    "test_model = T5ForConditionalGeneration.from_pretrained('t5-small', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "917334aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-small\",\n",
       "  \"architectures\": [\n",
       "    \"T5WithLMHeadModel\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.2,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 8,\n",
       "  \"num_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.3.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89e4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5470a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model.sample(input_ids)\n",
    "from transformers import (\n",
    "    LogitsProcessorList,\n",
    "    MinLengthLogitsProcessor,\n",
    "    BeamSearchScorer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e68cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = 'data/codex-m/test.txt'\n",
    "fname = 'data/{}/test.txt'.format(dataset_name)\n",
    "f = open(fname, 'r')\n",
    "data = []\n",
    "for line in f:\n",
    "    data.append(line.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdcdb004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10642"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247d8097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predict tail: walter harris (artist) | country of citizenship |\\tcanada'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c2394bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_wd_id_dict(filename):\n",
    "    out = {}\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        line = line.split('\\t')\n",
    "        out[line[1]] = line[0]\n",
    "    return out\n",
    "\n",
    "e2wdid = get_entity_wd_id_dict('data/wikidata5m/aliases.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240598bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# data_point = 'predict tail: novalis | occupation |    philosopher'\n",
    "id = 2\n",
    "data_point = data[id]\n",
    "encoder_input_str, target = data_point.split('\\t')\n",
    "encoder_input_str = [encoder_input_str]\n",
    "encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "num_beams = 2\n",
    "num_predictions = 2\n",
    "input_ids = torch.ones((len(encoder_input_str) * num_beams, 1), device=model.device, dtype=torch.long)\n",
    "input_ids = input_ids * model.config.decoder_start_token_id\n",
    "model_kwargs = {\n",
    "    \"encoder_outputs\": model.get_encoder()(encoder_input_ids.repeat_interleave(num_beams, dim=0), return_dict=True)\n",
    "}\n",
    "beam_scorer = BeamSearchScorer(\n",
    "    batch_size=len(encoder_input_str),\n",
    "    max_length=model.config.max_length,\n",
    "    num_beams=num_beams,\n",
    "    device=model.device,\n",
    "    num_beam_hyps_to_keep=num_predictions,\n",
    "    length_penalty=0.3\n",
    ")\n",
    "logits_processor = LogitsProcessorList([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3dfe273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict tail: mon oncle benjamin (movie) | original language of film or tv show |\n"
     ]
    }
   ],
   "source": [
    "input = 'predict tail: mon oncle benjamin (movie) | original language of film or tv show |'\n",
    "encoder_input_str = [input]\n",
    "encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "print(encoder_input_str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "eca081b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "languefrancaise\n"
     ]
    }
   ],
   "source": [
    "# outputs = model.beam_search(input_ids, beam_scorer, logits_processor=logits_processor, **model_kwargs)\n",
    "# print(\"Beam:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "outputs = model.generate(encoder_input_ids).tolist()[0]\n",
    "outputs = outputs[1:]\n",
    "outputs = outputs[:outputs.index(2)]\n",
    "print(tokenizer.sp.decode(outputs))\n",
    "# print('Target:', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3d685399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5221150'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2wdid['dante alighieri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b89c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdid2e = {v:k for k, v in e2wdid.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "89bcdafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'original language of film or tv show'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdid2e['P364']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63ef0801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m/s/doculation/doc/docantc'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sp.decode(outputs.tolist()[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf747a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d77eafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGreedyOutput(model, tokenizer, encoder_input_str):\n",
    "    encoder_input_str = [encoder_input_str]\n",
    "    encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(encoder_input_ids)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c64be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeamOutput(model, tokenizer, encoder_input_str, num_beams=10, \n",
    "                  num_predictions=3, length_penalty=1.0):\n",
    "    encoder_input_str = [encoder_input_str]\n",
    "    encoder_input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "#     encoder_input_ids = tokenizer(encoder_input_str, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\").input_ids\n",
    "    input_ids = torch.ones((len(encoder_input_str) * num_beams, 1), device=model.device, dtype=torch.long)\n",
    "    input_ids = input_ids * model.config.decoder_start_token_id\n",
    "    model_kwargs = {\n",
    "        \"encoder_outputs\": model.get_encoder()(encoder_input_ids.repeat_interleave(num_beams, dim=0), return_dict=True)\n",
    "    }\n",
    "    beam_scorer = BeamSearchScorer(\n",
    "        batch_size=len(encoder_input_str),\n",
    "        max_length=model.config.max_length,\n",
    "        num_beams=num_beams,\n",
    "        device=model.device,\n",
    "        num_beam_hyps_to_keep=num_predictions,\n",
    "        length_penalty=length_penalty\n",
    "    )\n",
    "    logits_processor = LogitsProcessorList([])\n",
    "    outputs = model.beam_search(input_ids, beam_scorer, logits_processor=logits_processor, **model_kwargs)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23eef50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3944fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:16,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'france', 'united kingdom of great britain and ireland', 'kingdom of italy'} Target: france\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:00<00:14,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'jean-baptiste dumas', 'francois-rene de chateaubriand', 'jean-baptiste biot'} Target: gaspard monge\n",
      "Predicted: {'film actor', 'singer-songwriter', 'film producer'} Target: mandolinist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:01<00:10,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julio iglesias', 'julia volkova'} Target: leon russell\n",
      "Predicted: {'film actor', 'singer-songwriter', 'philanthropist'} Target: singer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:01<00:08,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julia volkova', 'idina menzel'} Target: mos def\n",
      "Predicted: {'short story', 'symphony', 'novel'} Target: prose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:01<00:09,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'ivan andreyevich krylov', 'j. m. coetzeeeeeeeeeee', 'vladislav krapivin'} Target: max frisch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:02<00:09,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'saint petersburg', 'russian soviet federative socialist republic', 'moscow'} Target: soviet union\n",
      "Predicted: {'russian academy of sciences', 'academy of sciences of the ussr', 'saint petersburg academy of sciences'} Target: bulat okudzhava\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:02<00:07,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'saxophone', 'guitar', 'voice'} Target: guitar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:02<00:07,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'tamer hosny', 'julio iglesias', 'julia volkova'} Target: julio iglesias\n",
      "Predicted: {'science fiction writer', 'essayist', 'writer'} Target: playwright\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:03<00:06,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'ivan andreyevich krylov', 'j. m. coetzeeeeeeeeeee', 'vladislav krapivin'} Target: d. h. lawrence\n",
      "Predicted: {'pop music', 'rhythm and blues', 'contemporary r&b'} Target: hard rock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:03<00:06,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julio iglesias', 'julia volkova'} Target: myles kennedy\n",
      "Predicted: {'film actor', 'film director', 'film producer'} Target: producer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:03<00:05,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'tamer hosny', 'jimmy fallon', 'neil patrick harris'} Target: j. j. abrams\n",
      "Predicted: {'united states of america', 'egypt', 'sri lanka'} Target: thailand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:03<00:04,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {\"people's republic of china\", 'taiwan', 'united states of america'} Target: malaysia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:04<00:04,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'african union - united nations hybrid operation in darfur', 'organisation for the prohibition of chemical weapons', 'international telecommunication union'} Target: international finance corporation\n",
      "Predicted: {'senegal', 'egypt', 'sri lanka'} Target: madagascar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:04<00:05,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'musical composition', 'poetry', 'performing arts'} Target: performing arts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:04<00:05,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'j. m. coetzeeeeeeeeee', 'j. m. coetzeeeeeeeeeee', 't. s. eliot'} Target: serge gainsbourg\n",
      "Predicted: {'emi', 'columbia records', 'rca records'} Target: hollywood records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:05<00:04,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'julio iglesias', 'julia volkova', 'idina menzel'} Target: kevin jonas\n",
      "Predicted: {'warner bros. records', 'columbia records', 'rca records'} Target: warner music group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:05<00:04,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'joe walsh', 'julia volkova', 'idina menzel'} Target: kenny rogers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:05<00:04,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'russian academy of sciences', 'societe philomathique de paris', 'saint petersburg academy of sciences'} Target: german academy of sciences leopoldina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:06<00:03,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'george porter, baron porter of luddenham', 'carl friedrich von weizsacker', 'heinrich wilhelm gottfried von waldeyer-hartz'} Target: victor ambartsumian\n",
      "Predicted: {'science fiction writer', 'mathematician', 'physicist'} Target: chemist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:06<00:03,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'george porter, baron porter of luddenham', 'henry louis le chatelier', 'joseph-louis lagrange'} Target: james bryant conant\n",
      "Predicted: {'pedagogue', 'physicist', 'linguist'} Target: philosopher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:06<00:02,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'thomas aquinas', 'euclides da cunha', 'wilhelm von humboldt'} Target: franz miklosich\n",
      "Predicted: {'taiwan', 'germany', 'united states of america'} Target: indonesia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:07<00:02,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'syria', 'taiwan', 'sri lanka'} Target: bosnia and herzegovina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [00:07<00:02,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'african americans', 'ashkenazi jews', 'american jews'} Target: african americans\n",
      "Predicted: {'jimmy fallon', 'taylor momsen', 'john lennon'} Target: charlie wilson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:07<00:01,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'international centre for settlement of investment disputes', 'organisation for the prohibition of chemical weapons', 'international telecommunication union'} Target: universal postal union\n",
      "Predicted: {'guinea-bissau', 'egypt', 'sri lanka'} Target: luxembourg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:07<00:01,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'pedagogue', 'physicist', 'university teacher'} Target: musicologist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:08<00:01,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'ernst mayr', 'euclides da cunha', 'adriano celentano'} Target: max weber\n",
      "Predicted: {'pop music', 'rock music', 'rhythm and blues'} Target: disco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:08<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'taylor momsen', 'julia volkova', 'john lennon'} Target: valery leontiev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:08<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'united kingdom of great britain and ireland', 'kingdom of italy', 'united states of america'} Target: kingdom of italy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:09<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'francois-rene de chateaubriand', 'jean-jacques rousseau', 'euclides da cunha'} Target: augusto righi\n",
      "Predicted: {'organisation for economic cooperation and development', 'organisation for the prohibition of chemical weapons', 'international telecommunication union'} Target: international bank for reconstruction and development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [00:09<00:00,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'senegal', 'egypt', 'sri lanka'} Target: serbia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:09<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'sri lanka', 'united kingdom of great britain and ireland', 'united states of america'} Target: mexico\n",
      "Predicted: {'eugene ionesco', 'euclides da cunha', 'heinrich schliemann'} Target: gloria trevi\n",
      "0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# id = 100\n",
    "scorer_function = getBeamOutput \n",
    "# scorer_function = getGreedyOutput \n",
    "num_points = 50\n",
    "correct = 0\n",
    "for id in tqdm(range(0, num_points)):\n",
    "    data_point = data[id]\n",
    "    input, target = data_point.split('\\t')\n",
    "    predicted = set(scorer_function(model, tokenizer, input))\n",
    "    print(\"Predicted:\", predicted, \"Target:\", target)\n",
    "    if target in predicted:\n",
    "        correct += 1\n",
    "print(correct/num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80de7387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     3,  2160,    17,  1273, 22269,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d = data[0]\n",
    "# inputs, outputs = d.split('\\t')\n",
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "outputs = 'british english'\n",
    "x = tokenizer([inputs], return_tensors=\"pt\", add_special_tokens=True)\n",
    "input_ids = x.input_ids.to(model.device)\n",
    "attention_mask = x.attention_mask.to(model.device)\n",
    "labels = tokenizer([outputs], return_tensors=\"pt\").input_ids.to(model.device)\n",
    "target_tokens = tokenizer(outputs, return_tensors=\"pt\").input_ids[0]\n",
    "\n",
    "decoder_start_token_id = 0\n",
    "decoder_input_ids = (\n",
    "            torch.ones((input_ids.shape[0], 1), dtype=torch.long, device=input_ids.device) * decoder_start_token_id\n",
    "        )\n",
    "decoder_input_ids = torch.cat((decoder_input_ids,labels), dim=-1)\n",
    "decoder_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf70b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(input_ids = input_ids,\n",
    "         attention_mask=attention_mask,\n",
    "         labels=labels)\n",
    "\n",
    "# x = model(input_ids = input_ids,\n",
    "#          attention_mask=attention_mask,\n",
    "#          decoder_input_ids = decoder_input_ids)\n",
    "\n",
    "logits = x.logits[0]\n",
    "probs = torch.log_softmax(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "746a1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_file = 'data/{}/entity_strings.txt'.format(dataset_name)\n",
    "with open(entities_file) as f:\n",
    "    entities_strings = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "735a6f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f149351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def getScore(model, inputs, outputs):\n",
    "    x = tokenizer([inputs], return_tensors=\"pt\", add_special_tokens=True)\n",
    "    input_ids = x.input_ids.to(model.device)\n",
    "    labels = tokenizer([outputs], return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    target_tokens = labels[0]\n",
    "    model_output = model(input_ids = input_ids,\n",
    "             attention_mask=attention_mask,\n",
    "             labels=labels)\n",
    "    logits = model_output.logits[0]\n",
    "    probs = torch.log_softmax(logits, 1)\n",
    "    score = 0.0\n",
    "    for i, id in enumerate(target_tokens):\n",
    "        s = probs[i][id]\n",
    "        score += s\n",
    "    return score\n",
    "\n",
    "def getBatchScore(model, inputs, entities, batch_size=100):\n",
    "    scores = []\n",
    "    input_ids = tokenizer(inputs, return_tensors=\"pt\", add_special_tokens=True).input_ids.to(model.device)\n",
    "    for start_id in range(0, len(entities), batch_size):\n",
    "        entity_batch = entities[start_id:start_id + batch_size]\n",
    "        cur_batch_size = len(entity_batch)\n",
    "        batch_input_ids = input_ids.expand(cur_batch_size, -1)\n",
    "        labels = tokenizer(entity_batch, \n",
    "                           return_tensors=\"pt\",\n",
    "                           padding=True).input_ids.to(model.device)\n",
    "        model_output = model(input_ids = batch_input_ids,\n",
    "                         labels=labels)\n",
    "        logits = model_output.logits\n",
    "        probs = torch.log_softmax(logits, -1)\n",
    "        for i in range(cur_batch_size):\n",
    "            token_probs = probs[i]\n",
    "            entity_tokenized = labels[i]\n",
    "            entity_score = 0.0\n",
    "            for position, token_id in enumerate(entity_tokenized):\n",
    "                entity_score += token_probs[position][token_id]\n",
    "                if token_id == 1:\n",
    "                    break\n",
    "            scores.append(entity_score.item())\n",
    "    return np.array(scores)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae6c284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "inputs = data[0].split('\\t')[0]\n",
    "scores = getBatchScore(model, inputs, entities_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f7644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 162/3656 [06:55<2:31:33,  2.60s/it]"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for d in tqdm(data):\n",
    "    inputs = d.split('\\t')[0]\n",
    "    scores = getBatchScore(model, inputs, entities_strings)\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d0eb93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'russia'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = (-scores).argsort()[:10]\n",
    "entities_strings[top[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b78c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_np = np.array(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f238739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fname = 'codex-s_small_1gpu_20000_test_scores.pickle'\n",
    "pickle.dump(all_scores_np, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "f5b90668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16]) torch.Size([3, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9689,  9891,    10,  2876,    63, 21979,  1820,  8024, 11518,     6,\n",
       "          1545,     6,    42,  3814,  1820,     1],\n",
       "        [ 9689,  9891,    10,  2876,    63, 21979,  1820,  8024, 11518,     6,\n",
       "          1545,     6,    42,  3814,  1820,     1],\n",
       "        [ 9689,  9891,    10,  2876,    63, 21979,  1820,  8024, 11518,     6,\n",
       "          1545,     6,    42,  3814,  1820,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "input_ids = tokenizer(inputs, return_tensors=\"pt\", add_special_tokens=True).input_ids.to(model.device)\n",
    "input_ids.shape\n",
    "new_tensor = input_ids.expand(3,-1)\n",
    "print(input_ids.shape, new_tensor.shape)\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f16a00e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0665, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "outputs = 'english'\n",
    "getScore(model, inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "678ae2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17050/17050 [06:38<00:00, 42.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_score_entity = ''\n",
    "max_score = -9999999.\n",
    "inputs = 'predict tail: billy idol | languages spoken, written, or signed |'\n",
    "scores = np.array([])\n",
    "for e in tqdm(entities_strings):\n",
    "    outputs = e\n",
    "    s = getScore(model, inputs, outputs)\n",
    "    scores = np.append(scores, s.detach().cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2bde2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = (-scores).argsort()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97227722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'english'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_strings[top[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "be5bfcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.565360069274902\n"
     ]
    }
   ],
   "source": [
    "score = 0.0\n",
    "for i, id in enumerate(target_tokens):\n",
    "    s = probs[i][id]\n",
    "    score += s\n",
    "# score = torch.max(logits[0])\n",
    "print(score.item())\n",
    "# average_score_per_token = score.item()/(len(target_tokens))\n",
    "# print(average_score_per_token, len(target_tokens))\n",
    "# score = score.item()\n",
    "# print(score/len(target_tokens), score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "07686ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.8634,   4.0730,  -2.0617,  11.3171, -12.6902,  -0.2787,  -0.1332,\n",
      "          1.3992,   4.9949,   1.2909], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor(15.8887, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(logits[0][:10])\n",
    "print(torch.max(logits[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "612387f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁english']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([torch.argmax(logits[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33598803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import T5_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89cfc6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20622/20622 [00:00<00:00, 840393.08it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = T5_Dataset('test', dataset_name='codex-m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf51206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_accelerate import removePadding, eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8985d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 200\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b75ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:59<00:00,  1.74batches/s]\n"
     ]
    }
   ],
   "source": [
    "acc = eval(model, valid_dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03845319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10876733585491223"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de02c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = tokenizer(\"international development association\", return_tensors=\"pt\").input_ids[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033a792c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1038,  606, 6028,    1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "541e9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = outputs[0][1:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e357e189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1038,  2137,    21, 20532,    11,   606,     1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb42b5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual == predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a0b725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1038,  606, 6028,    1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f946f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

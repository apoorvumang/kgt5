{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f79530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from transformers import T5Config, T5ForConditionalGeneration\n",
    "from transformers.optimization import Adafactor\n",
    "import datasets\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "# from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "from sentencepiece_tokenizer import SentencePieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85835606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length padding enabled (needed for TPU)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SentencePieceTokenizer('sp_wd5m_v3', max_tokenize_length=32, pad_to_max=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "af4de6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/scratche/home/apoorv/repos/transformers/models/train-full-seq2seq-t5-small/checkpoint-90000'\n",
    "# folder = '/scratche/home/apoorv/repos/transformers/models/checkpoint-50000'\n",
    "# config = AutoConfig.from_pretrained(folder)\n",
    "# model = T5ForConditionalGeneration(config)\n",
    "model = T5ForConditionalGeneration.from_pretrained(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "00a154c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "s = \"|HEAD| human||| instance of\"\n",
    "tokenized = tokenizer([s], max_length=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6f329f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized\n",
    "# import torch\n",
    "# input_ids =  torch.LongTensor([[31190, 5, 2022, 6, 285, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "665bab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(input_ids)\n",
    "# print(tokenized.attention_mask)\n",
    "# tokenizer.input_ids =  torch.LongTensor([[31190, 5, 2022, 6, 285, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]],)\n",
    "# tokenizer.attention_mask = torch.LongTensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f7ab84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(input_ids = tokenized.input_ids, attention_mask = tokenized.attention_mask,\n",
    "                        eos_token_id = tokenizer.eos_token_id,\n",
    "                        pad_token_id = tokenizer.pad_token_id,\n",
    "                         temperature=1.0,\n",
    "                        do_sample=True,\n",
    "                         num_return_sequences=10\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "595c3c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "28589c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2],\n",
       "        [0, 2],\n",
       "        [0, 2],\n",
       "        [0, 2],\n",
       "        [0, 2],\n",
       "        [0, 2],\n",
       "        [0, 2],\n",
       "        [0, 2],\n",
       "        [0, 2],\n",
       "        [0, 2]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de54ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
